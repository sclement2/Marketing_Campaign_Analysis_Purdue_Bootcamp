{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adce0b95",
   "metadata": {},
   "source": [
    "# Hypothesis Testing\n",
    "\n",
    "Section: c. Store Sales Cannibalization by alternative distribution channels\n",
    "\n",
    "**Part of:** [marketing_campaign_082825_working.ipynb](./marketing_campaign_082825_working.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b05aa6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-06T21:13:01.253665Z",
     "iopub.status.busy": "2025-09-06T21:13:01.252666Z",
     "iopub.status.idle": "2025-09-06T21:13:03.231797Z",
     "shell.execute_reply": "2025-09-06T21:13:03.231797Z"
    }
   },
   "outputs": [],
   "source": [
    "# Setup and data loading\n",
    "from utils import (\n",
    "    ProjectConfig,\n",
    "    load_intermediate_results,\n",
    "    save_project_figure,\n",
    "    reset_plot_settings,\n",
    ")\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "config = ProjectConfig()\n",
    "# Load data from previous notebook\n",
    "df = load_intermediate_results(\"data_from_08_step_6.pkl\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adad7c08",
   "metadata": {
    "id": "FWjMLJSFd1dB"
   },
   "source": [
    "## c. Store Sales Cannibalization by alternative distribution channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4d994c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-06T21:13:03.234797Z",
     "iopub.status.busy": "2025-09-06T21:13:03.234797Z",
     "iopub.status.idle": "2025-09-06T21:13:03.248800Z",
     "shell.execute_reply": "2025-09-06T21:13:03.247796Z"
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1756043832149,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "GSASjOVMLT18"
   },
   "outputs": [],
   "source": [
    "# c. Store sales cannibalization\n",
    "\n",
    "# Specify H₀ and H₁:\n",
    "# H₀: The distributions of In-Store Purchases versus all the other Purchase Methods are\n",
    "#     identical (no difference in distribution).\n",
    "# H₁: The distribution of In-Store Purchass versus the other Purchase Methods is\n",
    "#     stochastically less (In-store purchase tends to be less than other purchase methods).\n",
    "\n",
    "# Normality and Test Choice:\n",
    "# •  Use the t-test if the data from the 3 purchase groups is approximately normally distributed.\n",
    "# •  Use the Mann-Whitney U test if the data is non-normal.\n",
    "\n",
    "#### Correlation Test Choices\n",
    "# Pearson:\n",
    "# •  Assumes linear relationships\n",
    "# •  Sensitive to outliers and skewness\n",
    "# •  Underestimates relationships in your data\n",
    "# Spearman:\n",
    "# •  Works with monotonic relationships\n",
    "# •  Robust to outliers\n",
    "# •  Better captures the true strength of relationships in your skewed data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b36a268",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-06T21:13:03.250802Z",
     "iopub.status.busy": "2025-09-06T21:13:03.250802Z",
     "iopub.status.idle": "2025-09-06T21:13:03.264801Z",
     "shell.execute_reply": "2025-09-06T21:13:03.263797Z"
    },
    "executionInfo": {
     "elapsed": 86,
     "status": "ok",
     "timestamp": 1756043832575,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "FaayvV34LT19"
   },
   "outputs": [],
   "source": [
    "# Extract relevant columns\n",
    "store_purchases = df['NumStorePurchases']\n",
    "catalog_purchases = df['NumCatalogPurchases']\n",
    "web_purchases = df['NumWebPurchases']\n",
    "total_purchases = df['Total_Purchases']\n",
    "alternate_purchases = df['NumWebPurchases'] + df['NumCatalogPurchases']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282d98b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-06T21:13:03.266799Z",
     "iopub.status.busy": "2025-09-06T21:13:03.266799Z",
     "iopub.status.idle": "2025-09-06T21:13:03.279796Z",
     "shell.execute_reply": "2025-09-06T21:13:03.279796Z"
    },
    "executionInfo": {
     "elapsed": 76,
     "status": "ok",
     "timestamp": 1756043832591,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "43q58CqliJnc"
   },
   "outputs": [],
   "source": [
    "cols = [\"NumStorePurchases\", \"NumWebPurchases\", \"NumCatalogPurchases\", \"Total_Purchases\"]\n",
    "df_cann = df[cols].dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4977bf33",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-09-06T21:13:03.282800Z",
     "iopub.status.busy": "2025-09-06T21:13:03.281799Z",
     "iopub.status.idle": "2025-09-06T21:13:03.374891Z",
     "shell.execute_reply": "2025-09-06T21:13:03.374383Z"
    },
    "executionInfo": {
     "elapsed": 83,
     "status": "ok",
     "timestamp": 1756043832621,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "xHr0NCZ6LT19",
    "outputId": "7c05f21c-7e16-4a27-eff9-5ed885f44c6e"
   },
   "outputs": [],
   "source": [
    "# Descriptive Statistics\n",
    "print(\"Descriptive Statistics:\")\n",
    "print(round(df_cann.describe(),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6af7d2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 757
    },
    "execution": {
     "iopub.execute_input": "2025-09-06T21:13:03.377902Z",
     "iopub.status.busy": "2025-09-06T21:13:03.377902Z",
     "iopub.status.idle": "2025-09-06T21:13:04.919022Z",
     "shell.execute_reply": "2025-09-06T21:13:04.918016Z"
    },
    "executionInfo": {
     "elapsed": 173,
     "status": "ok",
     "timestamp": 1756043832795,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "e3d3A6dSRtKg",
    "outputId": "ec54e26d-07e0-4730-b594-f82938091633"
   },
   "outputs": [],
   "source": [
    "# Create subplots for distribution analysis\n",
    "reset_plot_settings()\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Distribution of each purchase channel\n",
    "channels = ['NumWebPurchases', 'NumCatalogPurchases', 'NumStorePurchases']\n",
    "channel_labels = ['Web Purchases', 'Catalog Purchases', 'Store Purchases']\n",
    "\n",
    "for i, (channel, label) in enumerate(zip(channels, channel_labels)):\n",
    "    row = i // 2\n",
    "    col = i % 2\n",
    "\n",
    "    # Histogram with KDE overlay\n",
    "    sns.histplot(data=df, x=channel, kde=False, ax=axes[row, col], bins=20, color='salmon', stat='density')\n",
    "    sns.kdeplot(data=df, x=channel, ax=axes[row, col], color='navy', linewidth=2)\n",
    "    axes[row, col].set_title(f'Distribution of {label}')\n",
    "    axes[row, col].set_xlabel(label)\n",
    "\n",
    "# Box plot comparison\n",
    "sns.boxplot(data=df[channels], ax=axes[1, 1])\n",
    "axes[1, 1].set_title('Box Plot Comparison of Purchase Channels')\n",
    "axes[1, 1].set_xticklabels(['Web', 'Catalog', 'Store'])\n",
    "\n",
    "plt.tight_layout()\n",
    "save_project_figure(\n",
    "    \"Purchase_Channel_Distributions\",\n",
    "    \"Purchase Channel Distributions and Box Plot\",\n",
    "    config,\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "# Summary statistics\n",
    "print(\"Summary Statistics by Channel:\")\n",
    "summary_stats = df[channels].describe().T\n",
    "print(summary_stats)\n",
    "\n",
    "# Results\n",
    "# Purchase data is highly right skewed. Suggests that non-parametric hypothesis testing should be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88835b1f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "execution": {
     "iopub.execute_input": "2025-09-06T21:13:04.921019Z",
     "iopub.status.busy": "2025-09-06T21:13:04.921019Z",
     "iopub.status.idle": "2025-09-06T21:13:07.064886Z",
     "shell.execute_reply": "2025-09-06T21:13:07.063884Z"
    },
    "executionInfo": {
     "elapsed": 1379,
     "status": "ok",
     "timestamp": 1756052630982,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "rnwX8DxOUYFI",
    "outputId": "eb1cb441-ac9b-4651-f3cc-e2165152da08"
   },
   "outputs": [],
   "source": [
    "# Correlation matrix for purchase channels\n",
    "reset_plot_settings()\n",
    "\n",
    "# Calculate correlation matrix\n",
    "corr_matrix = df[channels].corr(method='spearman')\n",
    "\n",
    "# Create a new dataframe for the analysis\n",
    "df_corr = df.copy()\n",
    "# Create a new channel which is the sum of non-store purchases\n",
    "df_corr['AlternativeChannelPurchases'] = df_corr['NumWebPurchases'] + df_corr['NumCatalogPurchases']\n",
    "\n",
    "# Print correlation coefficients with p-values\n",
    "channels = ['NumWebPurchases', 'NumCatalogPurchases', 'NumStorePurchases']\n",
    "print(\"\\nDetailed Correlation Analysis:\")\n",
    "\n",
    "\n",
    "for i in range(len(channels)):\n",
    "    for j in range(i+1, len(channels)):\n",
    "        x = df_corr[channels[i]]\n",
    "        y = df_corr[channels[j]]\n",
    "\n",
    "        # Pearson correlation\n",
    "        p_corr, p_value = pearsonr(x, y)\n",
    "\n",
    "        # Spearman correlation\n",
    "        s_corr, s_value = spearmanr(x, y)\n",
    "\n",
    "        print(f\"\\n{channels[i]} vs {channels[j]}:\")\n",
    "        print(f\"   Pearson r={p_corr:.3f}, p={p_value:.4f}\")\n",
    "        print(f\"   Spearman r={s_corr:.3f}, p={s_value:.4f}\")\n",
    "\n",
    "        # ---- PLOTS ----\n",
    "        reset_plot_settings()\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "        # Scatter plot (raw)\n",
    "        axes[0].scatter(x, y, alpha=0.6)\n",
    "        axes[0].set_xlabel(channels[i])\n",
    "        axes[0].set_ylabel(channels[j])\n",
    "        axes[0].set_title(f\"Raw Scatter\\nPearson r={p_corr:.3f}\")\n",
    "\n",
    "        # Scatter plot (ranked)\n",
    "        rank_x = x.rank()\n",
    "        rank_y = y.rank()\n",
    "        sns.regplot(x=rank_x, y=rank_y,\n",
    "                    ax=axes[1],\n",
    "                    scatter_kws={'alpha': 0.6},\n",
    "                    color=\"orange\",\n",
    "                    line_kws={'color':'red', 'linestyle':'--', 'linewidth':2})\n",
    "        #axes[1].scatter(rank_x, rank_y, alpha=0.6, color=\"orange\")\n",
    "        axes[1].set_xlabel(f\"Rank of {channels[i]}\")\n",
    "        axes[1].set_ylabel(f\"Rank of {channels[j]}\")\n",
    "        axes[1].set_title(f\"Ranked Scatter\\nSpearman r={s_corr:.3f}\")\n",
    "\n",
    "        plt.suptitle(f\"{channels[i]} vs {channels[j]}\", fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        save_project_figure(\n",
    "            f\"{channels[i]}_vs_{channels[j]}\",\n",
    "            f\"{channels[i]} vs {channels[j]}\",\n",
    "            config,\n",
    "        )\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56614732",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-06T21:13:07.066886Z",
     "iopub.status.busy": "2025-09-06T21:13:07.066886Z",
     "iopub.status.idle": "2025-09-06T21:13:07.079885Z",
     "shell.execute_reply": "2025-09-06T21:13:07.078883Z"
    }
   },
   "outputs": [],
   "source": [
    "# Spearman vs Pearson:\n",
    "# Spearman is better for this analysis for several reasons:\n",
    "# 1. Consistently Higher Values: Spearman correlations are substantially higher across all comparisons (0.62-0.72 vs 0.41-0.56),\n",
    "#    suggesting the relationships are stronger than Pearson indicates.\n",
    "# 2. Non-linear Relationships: The raw scatter plots show clear evidence of non-linearity - clustered, stepped patterns rather\n",
    "#    than smooth linear trends. This is particularly evident in the catalog vs store plot.\n",
    "# 3. Outliers and Skewness: The scatter plots reveal outliers and skewed distributions that can suppress Pearson\n",
    "#    correlations but don’t affect Spearman.\n",
    "# 4. Count Data Characteristics: Purchase counts often follow non-normal distributions making rank-based correlation\n",
    "#    more appropriate.\n",
    "# The ranked scatter plots on the right show much cleaner, more linear relationships, confirming that Spearman better\n",
    "# captures the true strength of association between these purchase behaviors.\n",
    "\n",
    "# Use Spearman correlation for customer behavior analysis, as it provides a more accurate picture of the monotonic\n",
    "# relationships between different purchase channels.​​​​​​​​​​​​​​​​"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d76752a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 627
    },
    "execution": {
     "iopub.execute_input": "2025-09-06T21:13:07.082884Z",
     "iopub.status.busy": "2025-09-06T21:13:07.082884Z",
     "iopub.status.idle": "2025-09-06T21:13:08.945282Z",
     "shell.execute_reply": "2025-09-06T21:13:08.944277Z"
    },
    "executionInfo": {
     "elapsed": 1745,
     "status": "ok",
     "timestamp": 1756049140999,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "cS0w-TESlDK4",
    "outputId": "da4d6921-c924-4c20-ebe4-0b0fe296812a"
   },
   "outputs": [],
   "source": [
    "# Create comprehensive scatter plot analysis\n",
    "reset_plot_settings()\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "df_corr['RankedWebPurchases'] = df_corr['NumWebPurchases'].rank()\n",
    "df_corr['RankedCatalogPurchases'] = df_corr['NumCatalogPurchases'].rank()\n",
    "df_corr['RankedStorePurchases'] = df_corr['NumStorePurchases'].rank()\n",
    "df_corr['RankedAlternativeChannelPurchases'] = df_corr['AlternativeChannelPurchases'].rank()\n",
    "\n",
    "# Web vs Store\n",
    "sns.regplot(data=df_corr, x='RankedWebPurchases', y='RankedStorePurchases',\n",
    "            ax=axes[0, 0], scatter_kws={'alpha': 0.6}, color=\"orange\")\n",
    "axes[0, 0].set_title('Ranked Web Purchases vs Store Purchases', fontsize=14)\n",
    "axes[0, 0].set_xlabel('Ranked Web Purchases', fontsize=12)\n",
    "axes[0, 0].set_ylabel('Ranked Store Purchases', fontsize=12)\n",
    "\n",
    "# Catalog vs Store\n",
    "sns.regplot(data=df_corr, x='RankedCatalogPurchases', y='RankedStorePurchases',\n",
    "            ax=axes[0, 1], scatter_kws={'alpha': 0.6}, color=\"orange\")\n",
    "axes[0, 1].set_title('Ranked Catalog Purchases vs Store Purchases', fontsize=14)\n",
    "axes[0, 1].set_xlabel('Ranked Catalog Purchases', fontsize=12)\n",
    "axes[0, 1].set_ylabel('Ranked Store Purchases', fontsize=12)\n",
    "\n",
    "# Alternative Combined vs Store\n",
    "sns.regplot(data=df_corr, x='RankedAlternativeChannelPurchases', y='RankedStorePurchases',\n",
    "            ax=axes[1, 0], scatter_kws={'alpha': 0.6}, color=\"orange\")\n",
    "axes[1, 0].set_title('Ranked Total Alternative Channels vs Store Purchases', fontsize=14)\n",
    "axes[1, 0].set_xlabel('Ranked Total Alternative Channel Purchases', fontsize=12)\n",
    "axes[1, 0].set_ylabel('Ranked Store Purchases', fontsize=12)\n",
    "\n",
    "# Create heatmap with Spearman Correlation results\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0,\n",
    "            square=True, ax=axes[1,1], fmt='.3f')\n",
    "axes[1, 1].set_title('Spearman Correlation Matrix: Purchase Channels', fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "save_project_figure(\n",
    "    \"Comprehensive_Scatter_Plot_Analysis_for_Purchase_Channels\",\n",
    "    \"Comprehensive Scatter Plot Analysis for Purchase Channels\",\n",
    "    config,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098eaa32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-06T21:13:08.947280Z",
     "iopub.status.busy": "2025-09-06T21:13:08.947280Z",
     "iopub.status.idle": "2025-09-06T21:13:08.960277Z",
     "shell.execute_reply": "2025-09-06T21:13:08.960277Z"
    }
   },
   "outputs": [],
   "source": [
    "# Results\n",
    "# Correlation shows positive relationships between the various purchase methods\n",
    "# Strongest Relationship:\n",
    "# Catalog and store purchases show the highest correlation (Pearson r=0.56, Spearman r=0.72), suggesting customers\n",
    "# who buy from catalogs are also likely to shop in stores.\n",
    "\n",
    "# Moderate Relationships:\n",
    "# • Web and store purchases (Pearson r=0.50, Spearman r=0.67)\n",
    "# • Web and catalog purchases (Pearson r=0.41, Spearman r=0.62)\n",
    "\n",
    "# Results suggests customers tend to be multi-channel shoppers rather than exclusively using one purchase method.\n",
    "# The moderate-to-strong correlations indicate complementary rather than competing channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffe409c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-09-06T21:13:08.963280Z",
     "iopub.status.busy": "2025-09-06T21:13:08.962279Z",
     "iopub.status.idle": "2025-09-06T21:13:08.976278Z",
     "shell.execute_reply": "2025-09-06T21:13:08.976278Z"
    },
    "executionInfo": {
     "elapsed": 504,
     "status": "ok",
     "timestamp": 1756043833668,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "Gnmb_kG7LT19",
    "outputId": "1629ffc8-0df8-4733-b571-541fce063199"
   },
   "outputs": [],
   "source": [
    "# Normality check\n",
    "from scipy.stats import shapiro\n",
    "\n",
    "# Purpose:\n",
    "# •  Tests the null hypothesis (H₀) that the data from the groups is normally distributed.\n",
    "# •  Alternative hypothesis (H₁): The data is not normally distributed.\n",
    "\n",
    "for group, name in zip([store_purchases, web_purchases, catalog_purchases, alternate_purchases],['NumStorePurchases','NumWebPurchases','NumCatalogPurchases','AlternatePurchase']):\n",
    "    stat, p = shapiro(group)\n",
    "    print(f\"Shapiro-Wilk Test for {name}: W= {stat:.4f}, p-value = {p:.4f}\")\n",
    "    if p < 0.05:\n",
    "        print(\"p-value < 0.05: Reject H₀, data is not normally distributed.\")\n",
    "    else:\n",
    "        print(\"p-value >= 0.05: Fail to reject H₀, data may be normally distributed.\")\n",
    "\n",
    "# Use Mann-Whitney U test since it’s the direct non-parametric equivalent of the t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92c5fe3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-06T21:13:08.979279Z",
     "iopub.status.busy": "2025-09-06T21:13:08.978280Z",
     "iopub.status.idle": "2025-09-06T21:13:08.991277Z",
     "shell.execute_reply": "2025-09-06T21:13:08.991277Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import mannwhitneyu\n",
    "from statsmodels.stats.multitest import multipletests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ee626e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-06T21:13:08.994280Z",
     "iopub.status.busy": "2025-09-06T21:13:08.993279Z",
     "iopub.status.idle": "2025-09-06T21:13:09.007279Z",
     "shell.execute_reply": "2025-09-06T21:13:09.006277Z"
    }
   },
   "outputs": [],
   "source": [
    "# Hypothesis tests:\n",
    "# Test if web/catalog purchases negatively correlate with store purchases\n",
    "# Cannibalization requires store purchases to decrease when others increase\n",
    "# H0: High alternative channel users buy same/more in stores\n",
    "# H1: High alternative channel users buy LESS in stores (cannibalization)\n",
    "\n",
    "# high_web users equates to => df['NumWebPurchases'] > df['NumWebPurchases'].median()\n",
    "# high_catalog users equates to => df['NumCatalogPurchases'] > df['NumCatalogPurchases'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab45970c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-06T21:13:09.009281Z",
     "iopub.status.busy": "2025-09-06T21:13:09.008280Z",
     "iopub.status.idle": "2025-09-06T21:13:09.021277Z",
     "shell.execute_reply": "2025-09-06T21:13:09.021277Z"
    }
   },
   "outputs": [],
   "source": [
    "# Cannibalization looking at the medians:\n",
    "high_web = df_corr[df_corr['NumWebPurchases'] > df_corr['NumWebPurchases'].median()]\n",
    "low_web = df_corr[df_corr['NumWebPurchases'] <= df_corr['NumWebPurchases'].median()]\n",
    "\n",
    "high_catalog = df[df['NumCatalogPurchases'] > df['NumCatalogPurchases'].median()]\n",
    "low_catalog = df[df['NumCatalogPurchases'] <= df['NumCatalogPurchases'].median()]\n",
    "\n",
    "print(\"Web Cannibalization Test:\")\n",
    "print(f\"High web users - median store purchases: {high_web['NumStorePurchases'].median()}\")\n",
    "print(f\"Low web users - median store purchases: {low_web['NumStorePurchases'].median()}\")\n",
    "\n",
    "print(\"\\nCatalog Cannibalization Test:\")\n",
    "print(f\"High catalog users - median store purchases: {high_catalog['NumStorePurchases'].median()}\")\n",
    "print(f\"Low catalog users - median store purchases: {low_catalog['NumStorePurchases'].median()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ac02a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-06T21:13:09.024282Z",
     "iopub.status.busy": "2025-09-06T21:13:09.023279Z",
     "iopub.status.idle": "2025-09-06T21:13:09.037280Z",
     "shell.execute_reply": "2025-09-06T21:13:09.036277Z"
    }
   },
   "outputs": [],
   "source": [
    "def cannibalization_analysis_with_adjustment(df):\n",
    "    \"\"\"Complete cannibalization analysis with multiple comparison correction\"\"\"\n",
    "\n",
    "    # What Each Column Represents:\n",
    "    # - Original_p: Raw p-values from Mann-Whitney tests (no correction)\n",
    "    # - Bonferroni_p: Traditional Bonferroni correction (p × number_of_tests)\n",
    "    # - Holm_p: Holm-Bonferroni correction (sequential method)\n",
    "    # - FDR_p: False Discovery Rate correction (Benjamini-Hochberg)\n",
    "\n",
    "    # Why You're Comparing All Methods: Different Conservative Levels:_\n",
    "    # - Most Conservative: Traditional Bonferroni\n",
    "    # - Moderate: Holm-Bonferroni\n",
    "    # - Least Conservative: FDR (Benjamini-Hochberg)\n",
    "\n",
    "    tests = {}\n",
    "    p_values = []\n",
    "    test_names = []\n",
    "\n",
    "    # Test 1: Web cannibalization\n",
    "    high_web = df[df['NumWebPurchases'] > df['NumWebPurchases'].median()]\n",
    "    low_web = df[df['NumWebPurchases'] <= df['NumWebPurchases'].median()]\n",
    "    stat1, p1 = mannwhitneyu(high_web['NumStorePurchases'],\n",
    "                            low_web['NumStorePurchases'],\n",
    "                            alternative='less')\n",
    "\n",
    "    tests['web_cannibalization'] = {\n",
    "        'statistic': stat1,\n",
    "        'p_value': p1,\n",
    "        'high_median': high_web['NumStorePurchases'].median(),\n",
    "        'low_median': low_web['NumStorePurchases'].median()\n",
    "    }\n",
    "    p_values.append(p1)\n",
    "    test_names.append('Web Cannibalization')\n",
    "\n",
    "    # Test 2: Catalog cannibalization\n",
    "    high_catalog = df[df['NumCatalogPurchases'] > df['NumCatalogPurchases'].median()]\n",
    "    low_catalog = df[df['NumCatalogPurchases'] <= df['NumCatalogPurchases'].median()]\n",
    "    stat2, p2 = mannwhitneyu(high_catalog['NumStorePurchases'],\n",
    "                            low_catalog['NumStorePurchases'],\n",
    "                            alternative='less')\n",
    "\n",
    "    tests['catalog_cannibalization'] = {\n",
    "        'statistic': stat2,\n",
    "        'p_value': p2,\n",
    "        'high_median': high_catalog['NumStorePurchases'].median(),\n",
    "        'low_median': low_catalog['NumStorePurchases'].median()\n",
    "    }\n",
    "    p_values.append(p2)\n",
    "    test_names.append('Catalog Cannibalization')\n",
    "\n",
    "    # Multiple comparison adjustments\n",
    "    bonferroni = [min(p * len(p_values), 1.0) for p in p_values]\n",
    "    _, holm_adj, _, _ = multipletests(p_values, method='holm')\n",
    "    _, fdr_adj, _, _ = multipletests(p_values, method='fdr_bh')\n",
    "\n",
    "    # Results summary\n",
    "    import pandas as pd\n",
    "    results_df = pd.DataFrame({\n",
    "        'Test': test_names,\n",
    "        'Original_p': p_values,\n",
    "        'Bonferroni_p': bonferroni,\n",
    "        'Holm_p': holm_adj,\n",
    "        'FDR_p': fdr_adj,\n",
    "        'Significant_Original': [p < 0.05 for p in p_values],\n",
    "        'Significant_Bonferroni': [p < 0.05 for p in bonferroni],\n",
    "        'Significant_Holm': [p < 0.05 for p in holm_adj],\n",
    "        'Significant_FDR': [p < 0.05 for p in fdr_adj]\n",
    "    })\n",
    "\n",
    "    # What do the results mean?\n",
    "    # - Significant = False means \"Fail to reject the null hypothesis\"\n",
    "    # - Significant = True means \"Reject the null hypothesis\"\n",
    "\n",
    "    return tests, results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e9800e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-06T21:13:09.039280Z",
     "iopub.status.busy": "2025-09-06T21:13:09.038280Z",
     "iopub.status.idle": "2025-09-06T21:13:09.147280Z",
     "shell.execute_reply": "2025-09-06T21:13:09.146277Z"
    }
   },
   "outputs": [],
   "source": [
    "# Run the analysis\n",
    "tests, results = cannibalization_analysis_with_adjustment(df)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b04694e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-06T21:13:09.149280Z",
     "iopub.status.busy": "2025-09-06T21:13:09.149280Z",
     "iopub.status.idle": "2025-09-06T21:13:09.163280Z",
     "shell.execute_reply": "2025-09-06T21:13:09.162277Z"
    }
   },
   "outputs": [],
   "source": [
    "# What do the results mean?\n",
    "# Significant = False means \"Fail to reject the null hypothesis\"\n",
    "# The data completely contradicts the cannibalization hypothesis. P Value can't be larger than 1.0\n",
    "\n",
    "# Multiple Comparison Results:\n",
    "# All adjustment methods (Bonferroni, Holm-Bonferroni, FDR) gave identical results, confirming that:\n",
    "# • Robust conclusion - findings hold under different statistical assumptions\n",
    "# • No need to worry about multiple testing - results are so clear that correction doesn’t matter\n",
    "\n",
    "# Conclusion\n",
    "# Testing for cannibalization was performed using multiple statistical approaches with different levels\n",
    "# of conservatism. Regardless of the correction method used (Bonferroni, Holm-Bonferroni, or FDR),\n",
    "# no evidence of cannibalization (all p-values = 1.0), providing strong evidence that alternative channels\n",
    "# complement rather than compete with store sales.\n",
    "\n",
    "# Final Interpretation\n",
    "# There is no statistical evidence that web or catalog purchases cannibalize store sales. In fact, customers\n",
    "# who purchase heavily through alternative channels also tend to be heavy store shoppers, suggesting these\n",
    "# channels work synergistically rather than competitively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6039e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-06T21:13:09.165282Z",
     "iopub.status.busy": "2025-09-06T21:13:09.165282Z",
     "iopub.status.idle": "2025-09-06T21:13:09.177279Z",
     "shell.execute_reply": "2025-09-06T21:13:09.177279Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Save results for next notebook\n",
    "# save_intermediate_results(df_processed, 'processed_data.pkl', config)\n",
    "# save_intermediate_results(analysis_results, 'analysis_results.pkl', config)\n",
    "# print('✓ Results saved for next notebook')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
