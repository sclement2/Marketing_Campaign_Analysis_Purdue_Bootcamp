{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JGEt5Z8GdgFD"
   },
   "source": [
    "# Marketing Campaign Analysis\n",
    "\n",
    "This notebook performs exploratory data analysis and hypothesis testing on marketing campaign data to understand customer acquisition factors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DYtp9erX19WK",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Step 0: Load and Investigate the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 40,
     "status": "ok",
     "timestamp": 1756043824782,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "4xxjt0Gxe7Rc"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import rcParams\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1189,
     "status": "ok",
     "timestamp": 1756043826008,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "aqkpKXBddw1B",
    "outputId": "54941230-66c1-4711-9864-d4c4bd8938f8"
   },
   "outputs": [],
   "source": [
    "#if running Colab to connect to GDrive\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 66,
     "status": "ok",
     "timestamp": 1756043826019,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "Lr0VYCJheAOz"
   },
   "outputs": [],
   "source": [
    "# Filepath on GDrive\n",
    "# filepath = '/content/drive/MyDrive/School/SimpliLearn/PC DS-Applied Data Science with Python/End Projects/working/marketing_data.csv'\n",
    "\n",
    "# Filepath on local machine\n",
    "filepath = \"./data/marketing_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 55,
     "status": "ok",
     "timestamp": 1756043826032,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "EsahWXSkfBJA"
   },
   "outputs": [],
   "source": [
    "# Reading the data\n",
    "df = pd.read_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 64,
     "status": "ok",
     "timestamp": 1756043826061,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "cI-WFYZxg7kG"
   },
   "outputs": [],
   "source": [
    "# Investigate the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1756043826360,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "l-rjW_UHf9Us",
    "outputId": "bd77f51f-14cc-4448-b532-eb153e27b26e"
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1756043826390,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "9RP4QKbMyc-c"
   },
   "outputs": [],
   "source": [
    "# Fix the Income column name to remove the spaces\n",
    "df.rename(columns={' Income ': 'Income'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 47,
     "status": "ok",
     "timestamp": 1756043826462,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "BSgA0nbCgwkT",
    "outputId": "77961bb3-14f8-4de5-9975-7a4acbcd70b3"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GVuHVbMHfVWG",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Step 1: Examine Dt_Customer and Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 52,
     "status": "ok",
     "timestamp": 1756043826489,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "mtWodBqlfTSs",
    "outputId": "b6209e98-3440-41e7-a9ea-7630034eeb20"
   },
   "outputs": [],
   "source": [
    "# Step 1: Examine Dt_Customer and Income\n",
    "print(\"Initial Data Examination:\")\n",
    "print(\"\\nDt_Customer data type:\", df['Dt_Customer'].dtype)\n",
    "print(\"Income data type:\", df['Income'].dtype)\n",
    "print(\"\\nMissing values:\")\n",
    "print(df[['Dt_Customer', 'Income']].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1756043826528,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "s4TTtSA1gDNP",
    "outputId": "b871ff88-b55c-4266-a44c-f25411dd933f"
   },
   "outputs": [],
   "source": [
    "df[df['Income'].isnull()].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1756043826582,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "uE2YvdznhoYm",
    "outputId": "a7b39fb1-2dbe-4fdd-d04d-bf3e99cbe592"
   },
   "outputs": [],
   "source": [
    "# Cleaning Income column\n",
    "df['Income'] = df['Income'].str.replace('$', '').str.replace(',', '').str.strip()\n",
    "df['Income'] = pd.to_numeric(df['Income'], errors='coerce')\n",
    "df['Income'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 43,
     "status": "ok",
     "timestamp": 1756043826650,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "8Z5kp9eLyBwV",
    "outputId": "bc5d74fd-456b-45e6-a56d-1d0b4f60bb0f"
   },
   "outputs": [],
   "source": [
    "# Information after cleaning the Income column\n",
    "print(\"Number of NaN values for Income column:\",df['Income'].isna().sum())\n",
    "\n",
    "print(\"Basic Statistical Data for Income column:\")\n",
    "print(df['Income'].describe())\n",
    "# Missing values will be imputed later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1756043826708,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "YslzW86N5IfB"
   },
   "outputs": [],
   "source": [
    "# Converting Dt_Customer to datetime\n",
    "df['Dt_Customer'] = pd.to_datetime(df['Dt_Customer'], format='%m/%d/%y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 259,
     "status": "ok",
     "timestamp": 1756043827000,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "hU_FBIKc5Kft",
    "outputId": "cdeb4385-6176-42f0-a15d-35998706abab"
   },
   "outputs": [],
   "source": [
    "print(df['Dt_Customer'].head(10))\n",
    "df['Dt_Customer'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 171,
     "status": "ok",
     "timestamp": 1756043827001,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "HejQuU_8jVWU",
    "outputId": "b4038ed6-0106-4991-84ae-44fbe12fa5e9"
   },
   "outputs": [],
   "source": [
    "# Clean Education column\n",
    "print(\"Original Education values:\",df['Education'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 122,
     "status": "ok",
     "timestamp": 1756043827002,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "ngb5UxPqpTIT",
    "outputId": "5051f38a-90f9-4cdf-a428-d3a6dae479a5"
   },
   "outputs": [],
   "source": [
    "# Data Cleaning for Education\n",
    "# The instructions emphasize cleaning the Education categories.\n",
    "# The presence of 2n Cycle alongside Master suggests potential redundancy, as both likely refer\n",
    "# to postgraduate education. Basic is vague and may need clarification or standardization.\n",
    "\n",
    "# Here’s how cleansing the Education values was undertaken:\n",
    "# Merge 2n Cycle with Master: Since 2n Cycle corresponds to a Master’s degree in the Bologna Process,\n",
    "# combining it with Master standardizes the category to a more universally recognized term.\n",
    "# Clarify Basic: Without additional context, Basic likely represents education below a Bachelor’s degree\n",
    "# (e.g., high school or less). It will be renamed to something clearer: \"Secondary\"\n",
    "# Retain Graduation and rename to Bachelor\n",
    "\n",
    "df['Education'] = df['Education'].replace('2n Cycle', 'Master')\n",
    "df['Education'] = df['Education'].replace('Graduation', 'Bachelor')\n",
    "df['Education'] = df['Education'].replace('Basic', 'Secondary')\n",
    "\n",
    "print(\"Cleaned Education values:\",df['Education'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 67,
     "status": "ok",
     "timestamp": 1756043827003,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "AkAKCoOmkLuQ",
    "outputId": "7ea5296f-9711-462d-bcf0-64f7b5d9106b"
   },
   "outputs": [],
   "source": [
    "# Clean Marital_Status column\n",
    "print(\"Original Marital Status values:\",df['Marital_Status'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 44,
     "status": "ok",
     "timestamp": 1756043827019,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "XBlFfWEzsest",
    "outputId": "423e770c-ea3e-4e3d-f6f7-53d6c6e88292"
   },
   "outputs": [],
   "source": [
    "# The cleaning process used for merging non-standard categories in the Marital Status column\n",
    "# Merge (YOLO, Alone, Absurd) into a standard one (Single), reducing redundancy:\n",
    "# - YOLO (2 entries): Likely a joke or informal entry implying a single. Merging into Single.\n",
    "# - Alone (3 entries): Implies no partner, aligning with Single. Merging into Single.\n",
    "# - Absurd (2 entries): Ambiguous, but with such low frequency, it’s likely an error or non-standard\n",
    "# Retain Married, Together, Divorced, and Widow as distinct categories, as they reflect standard marital statuses.\n",
    "# - Married: 864 (standard, refers to legally married individuals)\n",
    "# - Together: 580 (likely refers to cohabiting partners, not legally married)\n",
    "# - Divorced: 232 (standard, refers to legally divorced individuals)\n",
    "# - Widow: 77 (standard, refers to individuals whose spouse has passed away)\n",
    "\n",
    "df['Marital_Status'] = df['Marital_Status'].replace(['YOLO', 'Alone', 'Absurd'], 'Single')\n",
    "print(\"\\nCleaned Marital_Status values:\",df['Marital_Status'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 44,
     "status": "ok",
     "timestamp": 1756043827064,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "Zirk6K4K7GJS",
    "outputId": "fd697863-4f70-4a06-d69f-56fb191dc51b"
   },
   "outputs": [],
   "source": [
    "# Calculate mean and median income by Marital Status and Education\n",
    "# Pivot tables for visualization\n",
    "mean_pivot = df.pivot_table(values='Income', index='Marital_Status', columns='Education',\n",
    "                           aggfunc='mean').round(2)\n",
    "median_pivot = df.pivot_table(values='Income', index='Marital_Status', columns='Education',\n",
    "                             aggfunc='median').round(2)\n",
    "\n",
    "print(\"\\nMean Income Pivot Table:\")\n",
    "print(mean_pivot)\n",
    "print(\"\\nMedian Income Pivot Table:\")\n",
    "print(median_pivot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DjqH08PYfbk2",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Step 2: Missing Value Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skewness = df[\"Income\"].skew()\n",
    "print(f\"\\nSkewness of Income distribution: {round(skewness, 2)}\")\n",
    "# The skewness value of 6.76 indicates extremely high positive skewness in income distribution\n",
    "# - Mean income will be substantially higher than median income\n",
    "# - Standard deviation may not accurately represent typical variation\n",
    "# - The bulk of data points cluster at lower income levels\n",
    "# - Use median instead of mean as a measure of central tendency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 311,
     "status": "ok",
     "timestamp": 1756043827390,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "4hfCQ1Nm8ygG"
   },
   "outputs": [],
   "source": [
    "# Impute missing Income values using the median income for the appropriate Education and Maritial_Status categories\n",
    "income_median = df.groupby(['Education', 'Marital_Status'])['Income'].median()\n",
    "def impute_income(row):\n",
    "    if pd.isna(row['Income']):\n",
    "        try:\n",
    "            return income_median[row['Education'], row['Marital_Status']]\n",
    "        except KeyError:\n",
    "            return df['Income'].median()  # Fallback to overall mean if combination is missing\n",
    "    return row['Income']\n",
    "df['Income'] = df.apply(impute_income, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 51,
     "status": "ok",
     "timestamp": 1756043827401,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "QGgXWPdM9mYL",
    "outputId": "fb62d838-db43-4c06-fd68-8442bb447127"
   },
   "outputs": [],
   "source": [
    "# Stats update post Input column update\n",
    "print(\"Missing values:\",df['Income'].isna().sum())\n",
    "print(\"Basic Statistical Data for Income column after imputation:\")\n",
    "print(df['Income'].describe().round(2))\n",
    "# Notice the count value has increased from 2216 to 2240 which has also altered the overall mean and median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 64,
     "status": "ok",
     "timestamp": 1756043827435,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "fF9VxrAkAtea",
    "outputId": "d65c2671-7b6c-44f0-ebef-019a0782d8d0"
   },
   "outputs": [],
   "source": [
    "median_pivot = df.pivot_table(values='Income', index='Marital_Status', columns='Education',\n",
    "                             aggfunc='median').round(2)\n",
    "\n",
    "print(\"\\nMedian Income Pivot Table:\")\n",
    "print(median_pivot)\n",
    "# The categorical median has been retained as seen in the updated pivot table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PmGaLIPafffT",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Step 3: Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 71,
     "status": "ok",
     "timestamp": 1756043827486,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "VVz8bnxcLT1z"
   },
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "current_year = 2025\n",
    "df['Age'] = current_year - df['Year_Birth']\n",
    "df['Total_Children'] = df['Kidhome'] + df['Teenhome']\n",
    "df['Total_Spending'] = df[['MntWines', 'MntFruits', 'MntMeatProducts',\n",
    "                          'MntFishProducts', 'MntSweetProducts', 'MntGoldProds']].sum(axis=1)\n",
    "df['Total_Purchases'] = df[['NumWebPurchases', 'NumCatalogPurchases', 'NumStorePurchases']].sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9sfn05JofN6G",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Step 4: Visualizations - Box Plots, Histograms, and Density Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 58,
     "status": "ok",
     "timestamp": 1756043827506,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "ze08byqvdNAR"
   },
   "outputs": [],
   "source": [
    "# Save current settings and plot reset\n",
    "original_rcParams = rcParams.copy()\n",
    "\n",
    "def reset_plot_settings():\n",
    "    \"\"\"Reset both matplotlib and seaborn to clean defaults\"\"\"\n",
    "    plt.close('all')  # Close existing figures\n",
    "    plt.rcdefaults()  # Reset matplotlib\n",
    "    sns.reset_defaults()  # Reset seaborn\n",
    "\n",
    "# Use between sections:\n",
    "reset_plot_settings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 338,
     "status": "ok",
     "timestamp": 1756043827806,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "pdQS456uLT1z",
    "outputId": "5093011b-bf21-4bfc-c6fe-eadbf8fa5e67"
   },
   "outputs": [],
   "source": [
    "# Step 4: Visualizations - Box Plots, Histograms, and Density Plots\n",
    "\n",
    "variables = [\"Age\", \"Income\", \"Total_Purchases\", \"Total_Spending\"]\n",
    "titles = [\"Age\", \"Income\", \"Total Purchases\", \"Total Spending\"]\n",
    "units = [\"Years\", \"USD\", \"Number\", \"USD\"]\n",
    "\n",
    "# Create a 4x3 subplot grid\n",
    "fig, axes = plt.subplots(nrows=4, ncols=2, figsize=(12, 12))\n",
    "\n",
    "for i, var in enumerate(variables):\n",
    "    # Boxplot\n",
    "    sns.boxplot(y=df[var], ax=axes[i, 0], color=\"skyblue\")\n",
    "    axes[i, 0].set_title(f\"{titles[i]} Boxplot\")\n",
    "    axes[i, 0].set_ylabel(units[i])\n",
    "\n",
    "    # Histogram with KDE overlay\n",
    "    sns.histplot(data=df, x=var, ax=axes[i, 1], bins=30, color=\"salmon\", stat=\"density\")\n",
    "    sns.kdeplot(data=df, x=var, ax=axes[i, 1], color=\"navy\", linewidth=2)\n",
    "    axes[i, 1].set_title(f\"{titles[i]} Histogram with KDE\")\n",
    "    axes[i, 1].set_xlabel(units[i])\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1756043827829,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "W5_MKMebLT1z",
    "outputId": "4d2f3fdd-dc8e-4f36-cab5-2a67930e0d36"
   },
   "outputs": [],
   "source": [
    "def find_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    print(f'Lower Bound: {lower_bound}')\n",
    "    df_lower = df[df[column] < lower_bound]\n",
    "    if df_lower[column].count() > 0:\n",
    "        print(f'Number of records below Lower Bound: {df_lower[column].count()}')\n",
    "        print(df_lower[column])\n",
    "    else:\n",
    "        print(f'Number of records below Lower Bound: {df_lower[column].count()}')\n",
    "\n",
    "    print(f'Upper Bound: {upper_bound}')\n",
    "    df_upper = df[df[column] > upper_bound]\n",
    "    if df_upper[column].count() > 0:\n",
    "        print(f'Number of records above Upper Bound: {df_upper[column].count()}')\n",
    "        print(df_upper[column])\n",
    "    else:\n",
    "        print(f'Number of records above Upper Bound: {df_upper[column].count()}')\n",
    "\n",
    "    #print(df[(df[column] >= lower_bound) & (df[column] <= upper_bound)][column].count())\n",
    "\n",
    "variables = ['Age','Income','Total_Purchases','Total_Spending']\n",
    "for var in variables:\n",
    "    print(f'\\n{var}')\n",
    "    find_outliers(df, var)\n",
    "\n",
    "# Results from the plots and outlier calculations show that for the variables Total_Purchases and Total_Spending\n",
    "# It does not make sense to remove any outliers. While the data is skewed the outlier data is relevant.\n",
    "\n",
    "# For the variables Age and Income different results are shown.\n",
    "# - For Age the 3 outlier values seem to be erroneous since the ages are above 93.\n",
    "#   The suggestion is to remove these rows.\n",
    "# - For Income 1 of the 8 values seems to be erroneous or at least drastically different than the rest\n",
    "#   of the data.\n",
    "#   The suggestion is to remove the rows with Income outliers above the upper bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 56,
     "status": "ok",
     "timestamp": 1756043827911,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "EiBuXa6DLT1z"
   },
   "outputs": [],
   "source": [
    "# Remove the outliers for Age and Income\n",
    "\n",
    "def remove_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "\n",
    "variables = ['Age','Income']\n",
    "for var in variables:\n",
    "    df = remove_outliers(df, var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Check to see if there are any negative values for age, income, total purchases, or total spending\n",
    "variables = [\"Age\", \"Income\", \"Total_Purchases\", \"Total_Spending\"]\n",
    "for var in variables:\n",
    "    print(df[df[var] < 0][var].count())\n",
    "# No negative values found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 1216,
     "status": "ok",
     "timestamp": 1756043829173,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "F9U-DguOLT1z",
    "outputId": "7299c43e-c2a5-480c-d687-df201ac7a889"
   },
   "outputs": [],
   "source": [
    "# Visualizations - Box Plots, Histograms, and Density Plots post removal of outlier values\n",
    "\n",
    "reset_plot_settings()\n",
    "\n",
    "variables = ['Age','Income','Total_Purchases','Total_Spending']\n",
    "titles = ['Age','Income','Total Purchases','Total Spending']\n",
    "units = ['Years','USD','Number','USD']\n",
    "\n",
    "# Create a 4x3 subplot grid\n",
    "fig, axes = plt.subplots(nrows=4, ncols=2, figsize=(12,12))\n",
    "\n",
    "for i, var in enumerate(variables):\n",
    "    # Boxplot\n",
    "    sns.boxplot(y=df[var], ax=axes[i,0], color='skyblue')\n",
    "    axes[i,0].set_title(f'{titles[i]} Boxplot')\n",
    "    axes[i,0].set_ylabel(units[i])\n",
    "\n",
    "    # Histogram with KDE overlay\n",
    "    sns.histplot(data=df, x=var, ax=axes[i,1], bins=30, color='salmon', stat='density')\n",
    "    sns.kdeplot(data=df, x=var, ax=axes[i,1], color='navy', linewidth=2)\n",
    "    axes[i,1].set_title(f'{titles[i]} Histogram with KDE')\n",
    "    axes[i,1].set_xlabel(units[i])\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# After removing outliers from Age and Income the box and histogram plots look\n",
    "# more like a normal curve. However Total Purchases and Total Spending are still\n",
    "# very heavilty right skewed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_pivot = df.pivot_table(\n",
    "    values=\"Income\", index=\"Marital_Status\", columns=\"Education\", aggfunc=\"median\"\n",
    ").round(2)\n",
    "\n",
    "print(\"\\nMedian Income Pivot Table:\")\n",
    "print(median_pivot)\n",
    "# The categorical median has been retained after removing the outliers except for the Divorced-Bachelors category where it has gone from 55635.00 to 55599.00 as seen in the updated pivot table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qz6bFMvPfGBu",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Step 5: Encoding Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 151,
     "status": "ok",
     "timestamp": 1756043829349,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "J1IEQofDLT10"
   },
   "outputs": [],
   "source": [
    "# Encoding Categorical Variables\n",
    "# Ordinal encoding for Education\n",
    "#print(df['Education'].value_counts())\n",
    "education_mapping = {'Secondary': 1, 'Bachelor': 2, 'Master': 3, 'PhD': 4}\n",
    "df['Education_Encoded'] = df['Education'].map(education_mapping)\n",
    "df.drop(columns=['Education'],inplace=True)\n",
    "#print(df['Education_Encoded'].value_counts())\n",
    "\n",
    "# One-hot encoding for Marital_Status and Country\n",
    "df = pd.get_dummies(df, columns=['Marital_Status', 'Country'], prefix=['Marital', 'Country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 130,
     "status": "ok",
     "timestamp": 1756043829367,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "KGiTIPZBLT10",
    "outputId": "f2743e5c-faf7-4e5c-9817-4633e3eadb95"
   },
   "outputs": [],
   "source": [
    "df.columns # df columns post encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nE1oQ4OXfAAG",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Step 6: Correlation Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 675,
     "status": "ok",
     "timestamp": 1756043829978,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "AcF5sIRRLT10",
    "outputId": "26632892-d24d-4218-a81b-4a74dd5d6826"
   },
   "outputs": [],
   "source": [
    "# Base Correlation Heatmap\n",
    "reset_plot_settings()\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "correlation_matrix = df[\n",
    "    [\n",
    "        \"Age\",\n",
    "        \"Income\",\n",
    "        \"Total_Children\",\n",
    "        \"Total_Spending\",\n",
    "        \"Total_Purchases\",\n",
    "        \"Education_Encoded\",\n",
    "        \"Recency\",\n",
    "        \"Response\",\n",
    "    ]\n",
    "].corr()\n",
    "sns.heatmap(\n",
    "    correlation_matrix,\n",
    "    annot=True,\n",
    "    cmap=\"coolwarm\",\n",
    "    center=0,\n",
    "    vmin=-1,\n",
    "    vmax=1,\n",
    "    fmt=\".2f\",\n",
    ")\n",
    "plt.title(\"Correlation Heatmap (Base Variables)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 815,
     "status": "ok",
     "timestamp": 1756043830796,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "FIF9xUEdLT10",
    "outputId": "6efd139d-8059-4c71-ae3c-3a7ddb09151f"
   },
   "outputs": [],
   "source": [
    "# Correlation Heatmap (Base Plus Products, Recency and Last Campaign Response)\n",
    "reset_plot_settings()\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "correlation_matrix = df[\n",
    "    [\n",
    "        \"Age\",\n",
    "        \"Income\",\n",
    "        \"Total_Children\",\n",
    "        \"Total_Spending\",\n",
    "        \"Total_Purchases\",\n",
    "        \"Education_Encoded\",\n",
    "        \"Recency\",\n",
    "        \"Response\",\n",
    "    ]\n",
    "].corr()\n",
    "sns.heatmap(\n",
    "    correlation_matrix,\n",
    "    annot=True,\n",
    "    cmap=\"coolwarm\",\n",
    "    center=0,\n",
    "    vmin=-1,\n",
    "    vmax=1,\n",
    "    fmt=\".2f\",\n",
    ")\n",
    "plt.title(\"Correlation Heatmap (Base Variables)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Heatmap (Base Plus Purchase Channels and Campaign Acceptance)\n",
    "reset_plot_settings()\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "correlation_matrix = df[\n",
    "    [\n",
    "        \"Age\",\n",
    "        \"Income\",\n",
    "        \"Total_Children\",\n",
    "        \"Total_Spending\",\n",
    "        \"Total_Purchases\",\n",
    "        \"Education_Encoded\",\n",
    "        \"NumDealsPurchases\",\n",
    "        \"NumWebPurchases\",\n",
    "        \"NumCatalogPurchases\",\n",
    "        \"NumStorePurchases\",\n",
    "        \"NumWebVisitsMonth\",\n",
    "        \"Response\",\n",
    "        \"AcceptedCmp3\",\n",
    "        \"AcceptedCmp4\",\n",
    "        \"AcceptedCmp5\",\n",
    "        \"AcceptedCmp1\",\n",
    "        \"AcceptedCmp2\",\n",
    "    ]\n",
    "].corr()\n",
    "sns.heatmap(\n",
    "    correlation_matrix,\n",
    "    annot=True,\n",
    "    cmap=\"coolwarm\",\n",
    "    center=0,\n",
    "    vmin=-1,\n",
    "    vmax=1,\n",
    "    fmt=\".2f\",\n",
    ")\n",
    "plt.title(\"Correlation Heatmap (Base Plus Purchase Channels and Campaign Acceptance)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KdriKDUSe3mh"
   },
   "source": [
    "# Step 7: Hypothesis Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c6WX5R4lezKn",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Older individuals prefer in-store shopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1756043830840,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "I89gTZreLT11"
   },
   "outputs": [],
   "source": [
    "# a. Older individuals prefer in-store shopping\n",
    "\n",
    "# Specify H₀ and H₁:\n",
    "# H₀: The distributions of NumStorePurchases for older and younger customers are\n",
    "#     identical (no difference in distribution).\n",
    "# H₁: The distributions of NumStorePurchases for older customers is stochastically\n",
    "#     greater (they tend to have higher values).\n",
    "\n",
    "# Normality and Test Choice:\n",
    "# •  Use the t-test if NumStorePurchases is approximately normally distributed.\n",
    "# •  Use the Mann-Whitney U test if the data is non-normal.\n",
    "\n",
    "# Interpreting Results:\n",
    "# •  P-value ≤ α (0.05): Reject H₀, concluding there is evidence that older customers have\n",
    "#    higher in-store purchases.\n",
    "# •  P-value > α: Fail to reject H₀, indicating insufficient evidence that older customers\n",
    "#    prefer in-store purchases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 52,
     "status": "ok",
     "timestamp": 1756043830948,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "M178rloiLT11"
   },
   "outputs": [],
   "source": [
    "# Split data\n",
    "older = df[df['Age'] >= df['Age'].median()]['NumStorePurchases']\n",
    "younger = df[df['Age'] < df['Age'].median()]['NumStorePurchases']\n",
    "df['Older'] = df['Age'] >= df['Age'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 84,
     "status": "ok",
     "timestamp": 1756043831103,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "l2ye0wFkLT11",
    "outputId": "86b9f32d-c689-4dbc-d947-2fcd98542a23"
   },
   "outputs": [],
   "source": [
    "# Normality check\n",
    "from scipy.stats import shapiro\n",
    "\n",
    "# Purpose:\n",
    "# •  Tests the null hypothesis (H₀) that the data from the groups is normally distributed.\n",
    "# •  Alternative hypothesis (H₁): The data is not normally distributed.\n",
    "\n",
    "for group, data in [(1, older), (0, younger)]:\n",
    "    stat, p = shapiro(data)\n",
    "    print(f\"Shapiro-Wilk Test for Older Individuals = {group}: p-value = {p:.4f}\")\n",
    "    if p < 0.05:\n",
    "        print(\"  p-value < 0.05: Reject H₀, data is not normally distributed.\")\n",
    "    else:\n",
    "        print(\"  p-value >= 0.05: Fail to reject H₀, data may be normally distributed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 426,
     "status": "ok",
     "timestamp": 1756043831557,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "CpgeSchDLT11",
    "outputId": "d26d7439-3394-437a-e00f-64ef4c83a96c"
   },
   "outputs": [],
   "source": [
    "# Create a figure with two subplots side by side\n",
    "reset_plot_settings()\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6), sharey=True)\n",
    "\n",
    "# Boxplot\n",
    "sns.boxplot(\n",
    "    x=\"Older\", y=\"NumStorePurchases\", data=df, ax=ax1, hue=\"Older\", legend=False\n",
    ")\n",
    "ax1.set_title(\"Box Plot of In-Store Purchases for Older Customers\")\n",
    "ax1.set_xlabel(\"Age\")\n",
    "ax1.set_xticks([0, 1], [\"Younger\", \"Older\"])\n",
    "ax1.set_ylabel(\"Number of Store Purchases\")\n",
    "# ax1.set_ylim(-2,28)\n",
    "ax1.grid(True, axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "# Violin Plot\n",
    "sns.violinplot(\n",
    "    x=\"Older\", data=df, y=\"NumStorePurchases\", legend=False, ax=ax2, hue=\"Older\"\n",
    ")\n",
    "ax2.set_title(\"Violin Plot of In-Store Purchases for Older Customers\")\n",
    "ax2.set_xlabel(\"Age\")\n",
    "ax2.set_xticks([0, 1], [\"Younger\", \"Older\"])\n",
    "ax2.grid(True, axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Descriptive Statistics\n",
    "current_stats = df.groupby(\"Older\")[\"NumStorePurchases\"].agg([\"mean\", \"median\", \"std\", \"count\"])\n",
    "print(\"\\nDescriptive Statistics\")\n",
    "print(current_stats)\n",
    "\n",
    "# Shapiro-Wilk test and plots show data is not normally distributed so a non-parametric\n",
    "# test seems more appropriate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 91,
     "status": "ok",
     "timestamp": 1756043831571,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "yJyp3yiKLT15",
    "outputId": "9eedaa91-73e9-41e3-f9bd-b59ca2fa827c"
   },
   "outputs": [],
   "source": [
    "# Perform Mann-Whitney U Test (One-Tailed)\n",
    "\n",
    "# H₀: The distributions of NumStorePurchases for older and younger customers are\n",
    "#     identical (no difference in distribution).\n",
    "# H₁: The distributions of NumStorePurchases for older is stochastically\n",
    "#     greater (they tend to have higher values).\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "stat, p_value = mannwhitneyu(older, younger, alternative='greater')\n",
    "print(f'Mann-Whitney U Test: statistic = {stat:.4f}, p-value = {p_value:.4f}')\n",
    "\n",
    "# Interpretation\n",
    "alpha = 0.05\n",
    "if p_value <= alpha:\n",
    "    print('Reject H₀: Older customer have higher in-store puchases')\n",
    "else:\n",
    "    print('Fail to reject H₀: No evidence that older customers have higher in-store purchases')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 70,
     "status": "ok",
     "timestamp": 1756043831573,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "OhjDcbvPLT16",
    "outputId": "f80b89c1-082e-4339-a55f-781a6ee8e765"
   },
   "outputs": [],
   "source": [
    "# Why a t-test may be ok\n",
    "# Large sample sizes (e.g., n > 30 or ideally n > 50 per group), due to the Central Limit Theorem (CLT).\n",
    "# The CLT states that the sampling distribution of the mean approaches normality as sample size increases,\n",
    "# even if the underlying data is non-normal.\n",
    "\n",
    "print(f\"Sample size for Older Customers:\\n{df['Older'].value_counts()}\")\n",
    "# Sample Size is Large: Both groups (Older = 1 and 0) have n > 50\n",
    "# the CLT helps ensure the t-test is robust."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 41,
     "status": "ok",
     "timestamp": 1756043831574,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "x851YYLyLT16",
    "outputId": "c19304c1-763d-4ae6-8e1a-3332e9fff29d"
   },
   "outputs": [],
   "source": [
    "# Perform Levene's test\n",
    "\n",
    "# Purpose:\n",
    "# •  Tests the null hypothesis (H₀) that the variances of the groups are equal.\n",
    "# •  Alternative hypothesis (H₁): The variances are not equal.\n",
    "\n",
    "# Variations of test:\n",
    "# •  Standard Levene’s Test: Uses the group mean for calculating deviations.\n",
    "# •  Modified Levene’s Test (Brown-Forsythe): Uses the group median instead of the mean,\n",
    "#    which is more robust to non-normal data.\n",
    "\n",
    "# Implications of test:\n",
    "# •  If Levene’s test indicates unequal variances (p-value ≤ 0.05), use Welch’s t-test to compare means.\n",
    "# •  If variances are equal, use the standard t-test.\n",
    "\n",
    "from scipy.stats import levene\n",
    "alpha = 0.05\n",
    "\n",
    "stat, p_levene = levene(older, younger, center='median')  # Use 'median' for Brown-Forsythe\n",
    "print(f\"Levene's Test: statistic = {stat:.4f}, p-value = {p_value:.4f}\")\n",
    "\n",
    "print(f\"{'Unequal variances' if p_levene < alpha else 'Equal variances'} (p {'<' if p_levene < alpha else '>='} {alpha})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1756043831597,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "Bs5MbdsZLT16",
    "outputId": "d02a5a2d-4ade-44cd-d4d9-8d3104862fa9"
   },
   "outputs": [],
   "source": [
    "# Unequal variances use Welch’s t-test to compare means\n",
    "# Run parametric Welch's t-test\n",
    "\n",
    "from scipy.stats import ttest_ind\n",
    "print(\"\\nWelch's t-Test (unequal variances):\")\n",
    "stat, p_welch = ttest_ind(older, younger, alternative='greater', equal_var=False)\n",
    "print(f\"Welch's t-test: statistic = {stat:.4f}, p-value = {p_welch:.4f}\")\n",
    "\n",
    "if p_welch <= alpha:\n",
    "    print('Reject H₀: Older customers have higher in-store puchases')\n",
    "else:\n",
    "    print('Fail to reject H₀: No evidence that older customers have higher in-store purchases')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1756043831623,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "wYNEzDUYLT16"
   },
   "outputs": [],
   "source": [
    "# Conclusion\n",
    "# Both the parametric test (Welch's t-Test) and the non-parametric test (Mann-Whitney U Test)\n",
    "# reject H₀, meaning there is evidence that older customers have more in-store purchases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aXL7WXdsgQ2n",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Customers with children prefer online shopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1756043831665,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "OjhzG18_LT17"
   },
   "outputs": [],
   "source": [
    "# b. Customers with children prefer online shopping\n",
    "\n",
    "# Specify H₀ and H₁:\n",
    "# H₀: The distributions of NumWebPurchases for customers with and without children are\n",
    "#     identical (no difference in distribution).\n",
    "# H₁: The distribution of NumWebPurchases for customers with children is stochastically\n",
    "#     greater (they tend to have higher values).\n",
    "\n",
    "# Normality and Test Choice:\n",
    "# •  Use the t-test if NumWebPurchases is approximately normally distributed.\n",
    "# •  Use the Mann-Whitney U test if the data is non-normal.\n",
    "\n",
    "# Interpreting Results:\n",
    "# •  P-value ≤ α (0.05): Reject H₀, concluding there is evidence that customers with children\n",
    "#    prefer online shopping.\n",
    "# •  P-value > α: Fail to reject H₀, indicating insufficient evidence that customers with children\n",
    "#    prefer online shopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 66,
     "status": "ok",
     "timestamp": 1756043831768,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "AzCShko5LT17"
   },
   "outputs": [],
   "source": [
    "# Split data\n",
    "df['Has_Children'] = df['Total_Children'] >= 1\n",
    "web_with_children = df[df['Has_Children'] == 1]['NumWebPurchases']\n",
    "web_without_children = df[df['Has_Children'] == 0]['NumWebPurchases']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 52,
     "status": "ok",
     "timestamp": 1756043831779,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "X1Mt0sNlLT17",
    "outputId": "40ab06a9-4ca8-416a-dd05-3615a840978b"
   },
   "outputs": [],
   "source": [
    "# Normality check\n",
    "from scipy.stats import shapiro\n",
    "\n",
    "# Purpose:\n",
    "# •  Tests the null hypothesis (H₀) that the data from the groups is normally distributed.\n",
    "# •  Alternative hypothesis (H₁): The data is not normally distributed.\n",
    "\n",
    "for group, data in [(1, web_with_children), (0, web_without_children)]:\n",
    "    stat, p = shapiro(data)\n",
    "    print(f\"Shapiro-Wilk Test for Has_Children = {group}: p-value = {p:.4f}\")\n",
    "    if p < 0.05:\n",
    "        print(\"  p-value < 0.05: Reject H₀, data is not normally distributed.\")\n",
    "    else:\n",
    "        print(\"  p-value >= 0.05: Fail to reject H₀, data may be normally distributed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 120,
     "status": "ok",
     "timestamp": 1756043831871,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "9SA6xgiBLT17",
    "outputId": "ac9ab3ab-6c85-4dd1-e119-77f4bb32059d"
   },
   "outputs": [],
   "source": [
    "# Create a figure with two subplots side by side\n",
    "\n",
    "reset_plot_settings()\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6), sharey=True)\n",
    "\n",
    "# Boxplot\n",
    "sns.boxplot(\n",
    "    x=\"Has_Children\",\n",
    "    y=\"NumWebPurchases\",\n",
    "    data=df,\n",
    "    ax=ax1,\n",
    "    hue=\"Has_Children\",\n",
    "    legend=False,\n",
    ")\n",
    "ax1.set_title(\"Box Plot of Web Purchases by Presence of Children\")\n",
    "ax1.set_ylabel(\"Number of Web Purchases\")\n",
    "ax1.set_xlabel(\"Children\")\n",
    "ax1.set_xticks([0, 1], [\"No Children\", \"Has Children\"])\n",
    "ax1.set_ylim(-2, 29)\n",
    "ax1.grid(True, axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "# Violin Plot\n",
    "sns.violinplot(\n",
    "    x=\"Has_Children\",\n",
    "    data=df,\n",
    "    y=\"NumWebPurchases\",\n",
    "    legend=False,\n",
    "    ax=ax2,\n",
    "    hue=\"Has_Children\",\n",
    ")\n",
    "ax2.set_title(\"Violin Plot of Web Purchases by Presence of Children\")\n",
    "ax2.set_xlabel(\"Children\")\n",
    "ax2.set_xticks([0, 1], [\"No Children\", \"Has Children\"])\n",
    "ax2.grid(True, axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Descriptive Statistics\n",
    "print(\"\\nDescriptive Statistics\")\n",
    "dfstats = df.groupby(\"Has_Children\")[\"NumWebPurchases\"].agg(\n",
    "    [\"mean\", \"median\", \"std\", \"count\"]\n",
    ")\n",
    "print(dfstats)\n",
    "\n",
    "# Shapiro-Wilk test and plots show data is not normally distributed so a non-parametric\n",
    "# test seems more appropriate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 64,
     "status": "ok",
     "timestamp": 1756043831907,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "mu1Ar9fOLT17",
    "outputId": "45702abf-d6a7-421e-a1f7-4dcc506f29aa"
   },
   "outputs": [],
   "source": [
    "# Perform Mann-Whitney U Test (One-Tailed)\n",
    "# H₀: The distributions of NumWebPurchases for customers with and without children are\n",
    "#     identical (no difference in distribution).\n",
    "# H₁: The distribution of NumWebPurchases for customers with children is greater\n",
    "#     (they tend to have higher values).\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "stat, p_value = mannwhitneyu(web_with_children, web_without_children, alternative='greater')\n",
    "print(f'Mann-Whitney U Test: statistic = {stat:.4f}, p-value = {p_value:.4f}')\n",
    "\n",
    "# Interpretation\n",
    "alpha = 0.05\n",
    "if p_value <= alpha:\n",
    "    print('Reject H₀: Customers with children have higher web puchases puchases')\n",
    "else:\n",
    "    print('Fail to reject H₀: No evidence that customers with children have higher web purchases')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 48,
     "status": "ok",
     "timestamp": 1756043831936,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "Pz0zAK-ALT18",
    "outputId": "800307fd-506e-4157-83d9-09e34fa1a4ec"
   },
   "outputs": [],
   "source": [
    "# Why a t-test may be ok\n",
    "# Large sample sizes (e.g., n > 30 or ideally n > 50 per group), due to the Central Limit Theorem (CLT).\n",
    "# The CLT states that the sampling distribution of the mean approaches normality as sample size increases,\n",
    "# even if the underlying data is non-normal.\n",
    "\n",
    "print(f\"Sample size for Has_Children:\\n{df['Has_Children'].value_counts()}\")\n",
    "# Sample Size is Large: Both groups (HasChildren = 1 and 0) have n > 50\n",
    "# the CLT helps ensure the t-test is robust."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1756043831962,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "AC1LEVkGLT18",
    "outputId": "4c63df32-c7ad-4e8e-e674-3acf3f3b0805"
   },
   "outputs": [],
   "source": [
    "# Perform Levene's test\n",
    "\n",
    "# Purpose:\n",
    "# •  Tests the null hypothesis (H₀) that the variances of the groups are equal.\n",
    "# •  Alternative hypothesis (H₁): The variances are not equal.\n",
    "\n",
    "# Variations of test:\n",
    "# •  Standard Levene’s Test: Uses the group mean for calculating deviations.\n",
    "# •  Modified Levene’s Test (Brown-Forsythe): Uses the group median instead of the mean,\n",
    "#    which is more robust to non-normal data.\n",
    "\n",
    "# Implications of test:\n",
    "# •  If Levene’s test indicates unequal variances (p-value ≤ 0.05), use Welch’s t-test to compare means.\n",
    "# •  If variances are equal, use the standard t-test.\n",
    "\n",
    "from scipy.stats import levene\n",
    "alpha = 0.05\n",
    "\n",
    "stat, p_levene = levene(web_with_children, web_without_children, center='median')\n",
    "print(f\"\\nLevene's Test: statistic = {stat:.4f}, p-value = {p_levene:.4f}\")\n",
    "print(f\"{'Unequal variances' if p_levene < alpha else 'Equal variances'} (p {'<' if p_levene < alpha else '>='} {alpha})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1756043832009,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "soy9dgjmLT18",
    "outputId": "fbf4c86e-2743-422e-c19b-ae0ee36ec6e4"
   },
   "outputs": [],
   "source": [
    "# Unequal variances use Welch’s t-test to compare means\n",
    "# Run parametric Welch's t-test\n",
    "\n",
    "from scipy.stats import ttest_ind\n",
    "print(\"\\nWelch's t-Test (unequal variances):\")\n",
    "stat, p_welch = ttest_ind(web_with_children, web_without_children, alternative='greater', equal_var=False)\n",
    "print(f\"Welch's t-test: statistic = {stat:.4f}, p-value = {p_welch:.4f}\")\n",
    "\n",
    "if p_welch <= alpha:\n",
    "    print('Reject H₀: Customers with children have higher web puchases puchases')\n",
    "else:\n",
    "    print('Fail to reject H₀: No evidence that customers with children have higher web purchases')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1756043832089,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "exIT9PsYLT18"
   },
   "outputs": [],
   "source": [
    "# Conclusion\n",
    "# Both the parametric test (Welch's t-Test) and the non-parametric test (Mann-Whitney U Test)\n",
    "# fail to reject H₀, meaning there is no evidence that customers with children have higher web purchases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FWjMLJSFd1dB",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## c. Store Sales Cannibalization by alternative distribution channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1756043832149,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "GSASjOVMLT18"
   },
   "outputs": [],
   "source": [
    "# c. Store sales cannibalization\n",
    "\n",
    "# Specify H₀ and H₁:\n",
    "# H₀: The distributions of In-Store Purchases versus all the other Purchase Methods are\n",
    "#     identical (no difference in distribution).\n",
    "# H₁: The distribution of In-Store Purchass versus the other Purchase Methods is\n",
    "#     stochastically less (In-store purchase tends to be less than other purchase methods).\n",
    "\n",
    "# Normality and Test Choice:\n",
    "# •  Use the t-test if the data from the 3 purchase groups is approximately normally distributed.\n",
    "# •  Use the Mann-Whitney U test if the data is non-normal.\n",
    "\n",
    "#### Correlation Test Choices\n",
    "# Pearson:\n",
    "# •  Assumes linear relationships\n",
    "# •  Sensitive to outliers and skewness\n",
    "# •  Underestimates relationships in your data\n",
    "# Spearman:\n",
    "# •  Works with monotonic relationships\n",
    "# •  Robust to outliers\n",
    "# •  Better captures the true strength of relationships in your skewed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 86,
     "status": "ok",
     "timestamp": 1756043832575,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "FaayvV34LT19"
   },
   "outputs": [],
   "source": [
    "# Extract relevant columns\n",
    "store_purchases = df['NumStorePurchases']\n",
    "catalog_purchases = df['NumCatalogPurchases']\n",
    "web_purchases = df['NumWebPurchases']\n",
    "total_purchases = df['Total_Purchases']\n",
    "alternate_purchases = df['NumWebPurchases'] + df['NumCatalogPurchases']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 76,
     "status": "ok",
     "timestamp": 1756043832591,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "43q58CqliJnc"
   },
   "outputs": [],
   "source": [
    "cols = [\"NumStorePurchases\", \"NumWebPurchases\", \"NumCatalogPurchases\", \"Total_Purchases\"]\n",
    "df_cann = df[cols].dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 83,
     "status": "ok",
     "timestamp": 1756043832621,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "xHr0NCZ6LT19",
    "outputId": "7c05f21c-7e16-4a27-eff9-5ed885f44c6e"
   },
   "outputs": [],
   "source": [
    "# Descriptive Statistics\n",
    "print(\"Descriptive Statistics:\")\n",
    "print(round(df_cann.describe(),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 757
    },
    "executionInfo": {
     "elapsed": 173,
     "status": "ok",
     "timestamp": 1756043832795,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "e3d3A6dSRtKg",
    "outputId": "ec54e26d-07e0-4730-b594-f82938091633"
   },
   "outputs": [],
   "source": [
    "# Create subplots for distribution analysis\n",
    "reset_plot_settings()\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Distribution of each purchase channel\n",
    "channels = [\"NumWebPurchases\", \"NumCatalogPurchases\", \"NumStorePurchases\"]\n",
    "channel_labels = [\"Web Purchases\", \"Catalog Purchases\", \"Store Purchases\"]\n",
    "\n",
    "for i, (channel, label) in enumerate(zip(channels, channel_labels)):\n",
    "    row = i // 2\n",
    "    col = i % 2\n",
    "\n",
    "    # Histogram with KDE overlay\n",
    "    sns.histplot(\n",
    "        data=df,\n",
    "        x=channel,\n",
    "        kde=False,\n",
    "        ax=axes[row, col],\n",
    "        bins=20,\n",
    "        color=\"salmon\",\n",
    "        stat=\"density\",\n",
    "    )\n",
    "    sns.kdeplot(data=df, x=channel, ax=axes[row, col], color=\"navy\", linewidth=2)\n",
    "    axes[row, col].set_title(f\"Distribution of {label}\")\n",
    "    axes[row, col].set_xlabel(label)\n",
    "\n",
    "# Box plot comparison\n",
    "sns.boxplot(data=df[channels], ax=axes[1, 1])\n",
    "axes[1, 1].set_title(\"Box Plot Comparison of Purchase Channels\")\n",
    "axes[1, 1].set_xticklabels([\"Web\", \"Catalog\", \"Store\"])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary statistics\n",
    "print(\"Summary Statistics by Channel:\")\n",
    "summary_stats = df[channels].describe().T\n",
    "print(summary_stats)\n",
    "\n",
    "# Results\n",
    "# Purchase data is highly right skewed. Suggests that non-parametric hypothesis testing should be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1379,
     "status": "ok",
     "timestamp": 1756052630982,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "rnwX8DxOUYFI",
    "outputId": "eb1cb441-ac9b-4651-f3cc-e2165152da08"
   },
   "outputs": [],
   "source": [
    "# Correlation matrix for purchase channels\n",
    "reset_plot_settings()\n",
    "\n",
    "# Calculate correlation matrix\n",
    "corr_matrix = df[channels].corr(method=\"spearman\")\n",
    "\n",
    "# Create a new dataframe for the analysis\n",
    "df_corr = df.copy()\n",
    "# Create a new channel which is the sum of non-store purchases\n",
    "df_corr[\"AlternativeChannelPurchases\"] = (\n",
    "    df_corr[\"NumWebPurchases\"] + df_corr[\"NumCatalogPurchases\"]\n",
    ")\n",
    "\n",
    "# Print correlation coefficients with p-values\n",
    "channels = [\"NumWebPurchases\", \"NumCatalogPurchases\", \"NumStorePurchases\"]\n",
    "print(\"\\nDetailed Correlation Analysis:\")\n",
    "\n",
    "\n",
    "for i in range(len(channels)):\n",
    "    for j in range(i + 1, len(channels)):\n",
    "        x = df_corr[channels[i]]\n",
    "        y = df_corr[channels[j]]\n",
    "\n",
    "        # Pearson correlation\n",
    "        p_corr, p_value = pearsonr(x, y)\n",
    "\n",
    "        # Spearman correlation\n",
    "        s_corr, s_value = spearmanr(x, y)\n",
    "\n",
    "        print(f\"\\n{channels[i]} vs {channels[j]}:\")\n",
    "        print(f\"   Pearson r={p_corr:.3f}, p={p_value:.4f}\")\n",
    "        print(f\"   Spearman r={s_corr:.3f}, p={s_value:.4f}\")\n",
    "\n",
    "        # ---- PLOTS ----\n",
    "        reset_plot_settings()\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "        # Scatter plot (raw)\n",
    "        axes[0].scatter(x, y, alpha=0.6)\n",
    "        axes[0].set_xlabel(channels[i])\n",
    "        axes[0].set_ylabel(channels[j])\n",
    "        axes[0].set_title(f\"Raw Scatter\\nPearson r={p_corr:.3f}\")\n",
    "\n",
    "        # Scatter plot (ranked)\n",
    "        rank_x = x.rank()\n",
    "        rank_y = y.rank()\n",
    "        sns.regplot(\n",
    "            x=rank_x,\n",
    "            y=rank_y,\n",
    "            ax=axes[1],\n",
    "            scatter_kws={\"alpha\": 0.6},\n",
    "            color=\"orange\",\n",
    "            line_kws={\"color\": \"red\", \"linestyle\": \"--\", \"linewidth\": 2},\n",
    "        )\n",
    "        # axes[1].scatter(rank_x, rank_y, alpha=0.6, color=\"orange\")\n",
    "        axes[1].set_xlabel(f\"Rank of {channels[i]}\")\n",
    "        axes[1].set_ylabel(f\"Rank of {channels[j]}\")\n",
    "        axes[1].set_title(f\"Ranked Scatter\\nSpearman r={s_corr:.3f}\")\n",
    "\n",
    "        plt.suptitle(f\"{channels[i]} vs {channels[j]}\", fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spearman vs Pearson:\n",
    "# Spearman is better for this analysis for several reasons:\n",
    "# 1. Consistently Higher Values: Spearman correlations are substantially higher across all comparisons (0.62-0.72 vs 0.41-0.56),\n",
    "#    suggesting the relationships are stronger than Pearson indicates.\n",
    "# 2. Non-linear Relationships: The raw scatter plots show clear evidence of non-linearity - clustered, stepped patterns rather\n",
    "#    than smooth linear trends. This is particularly evident in the catalog vs store plot.\n",
    "# 3. Outliers and Skewness: The scatter plots reveal outliers and skewed distributions that can suppress Pearson\n",
    "#    correlations but don’t affect Spearman.\n",
    "# 4. Count Data Characteristics: Purchase counts often follow non-normal distributions making rank-based correlation\n",
    "#    more appropriate.\n",
    "# The ranked scatter plots on the right show much cleaner, more linear relationships, confirming that Spearman better\n",
    "# captures the true strength of association between these purchase behaviors.\n",
    "\n",
    "# Use Spearman correlation for customer behavior analysis, as it provides a more accurate picture of the monotonic\n",
    "# relationships between different purchase channels.​​​​​​​​​​​​​​​​"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 627
    },
    "executionInfo": {
     "elapsed": 1745,
     "status": "ok",
     "timestamp": 1756049140999,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "cS0w-TESlDK4",
    "outputId": "da4d6921-c924-4c20-ebe4-0b0fe296812a"
   },
   "outputs": [],
   "source": [
    "# Create comprehensive scatter plot analysis\n",
    "reset_plot_settings()\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "df_corr[\"RankedWebPurchases\"] = df_corr[\"NumWebPurchases\"].rank()\n",
    "df_corr[\"RankedCatalogPurchases\"] = df_corr[\"NumCatalogPurchases\"].rank()\n",
    "df_corr[\"RankedStorePurchases\"] = df_corr[\"NumStorePurchases\"].rank()\n",
    "df_corr[\"RankedAlternativeChannelPurchases\"] = df_corr[\n",
    "    \"AlternativeChannelPurchases\"\n",
    "].rank()\n",
    "\n",
    "# Web vs Store\n",
    "sns.regplot(\n",
    "    data=df_corr,\n",
    "    x=\"RankedWebPurchases\",\n",
    "    y=\"RankedStorePurchases\",\n",
    "    ax=axes[0, 0],\n",
    "    scatter_kws={\"alpha\": 0.6},\n",
    "    color=\"orange\",\n",
    ")\n",
    "axes[0, 0].set_title(\"Ranked Web Purchases vs Store Purchases\", fontsize=14)\n",
    "axes[0, 0].set_xlabel(\"Ranked Web Purchases\", fontsize=12)\n",
    "axes[0, 0].set_ylabel(\"Ranked Store Purchases\", fontsize=12)\n",
    "\n",
    "# Catalog vs Store\n",
    "sns.regplot(\n",
    "    data=df_corr,\n",
    "    x=\"RankedCatalogPurchases\",\n",
    "    y=\"RankedStorePurchases\",\n",
    "    ax=axes[0, 1],\n",
    "    scatter_kws={\"alpha\": 0.6},\n",
    "    color=\"orange\",\n",
    ")\n",
    "axes[0, 1].set_title(\"Ranked Catalog Purchases vs Store Purchases\", fontsize=14)\n",
    "axes[0, 1].set_xlabel(\"Ranked Catalog Purchases\", fontsize=12)\n",
    "axes[0, 1].set_ylabel(\"Ranked Store Purchases\", fontsize=12)\n",
    "\n",
    "# Alternative Combined vs Store\n",
    "sns.regplot(\n",
    "    data=df_corr,\n",
    "    x=\"RankedAlternativeChannelPurchases\",\n",
    "    y=\"RankedStorePurchases\",\n",
    "    ax=axes[1, 0],\n",
    "    scatter_kws={\"alpha\": 0.6},\n",
    "    color=\"orange\",\n",
    ")\n",
    "axes[1, 0].set_title(\n",
    "    \"Ranked Total Alternative Channels vs Store Purchases\", fontsize=14\n",
    ")\n",
    "axes[1, 0].set_xlabel(\"Ranked Total Alternative Channel Purchases\", fontsize=12)\n",
    "axes[1, 0].set_ylabel(\"Ranked Store Purchases\", fontsize=12)\n",
    "\n",
    "# Create heatmap with Spearman Correlation results\n",
    "sns.heatmap(\n",
    "    corr_matrix,\n",
    "    annot=True,\n",
    "    cmap=\"coolwarm\",\n",
    "    center=0,\n",
    "    square=True,\n",
    "    ax=axes[1, 1],\n",
    "    fmt=\".3f\",\n",
    ")\n",
    "axes[1, 1].set_title(\"Spearman Correlation Matrix: Purchase Channels\", fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results\n",
    "# Correlation shows positive relationships between the various purchase methods\n",
    "# Strongest Relationship:\n",
    "# Catalog and store purchases show the highest correlation (Pearson r=0.56, Spearman r=0.72), suggesting customers\n",
    "# who buy from catalogs are also likely to shop in stores.\n",
    "\n",
    "# Moderate Relationships:\n",
    "# • Web and store purchases (Pearson r=0.50, Spearman r=0.67)\n",
    "# • Web and catalog purchases (Pearson r=0.41, Spearman r=0.62)\n",
    "\n",
    "# Results suggests customers tend to be multi-channel shoppers rather than exclusively using one purchase method.\n",
    "# The moderate-to-strong correlations indicate complementary rather than competing channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 504,
     "status": "ok",
     "timestamp": 1756043833668,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "Gnmb_kG7LT19",
    "outputId": "1629ffc8-0df8-4733-b571-541fce063199"
   },
   "outputs": [],
   "source": [
    "# Normality check\n",
    "from scipy.stats import shapiro\n",
    "\n",
    "# Purpose:\n",
    "# •  Tests the null hypothesis (H₀) that the data from the groups is normally distributed.\n",
    "# •  Alternative hypothesis (H₁): The data is not normally distributed.\n",
    "\n",
    "for group, name in zip(\n",
    "    [store_purchases, web_purchases, catalog_purchases, alternate_purchases],\n",
    "    [\n",
    "        \"NumStorePurchases\",\n",
    "        \"NumWebPurchases\",\n",
    "        \"NumCatalogPurchases\",\n",
    "        \"AlternatePurchase\",\n",
    "    ],\n",
    "):\n",
    "    stat, p = shapiro(group)\n",
    "    print(f\"Shapiro-Wilk Test for {name}: W= {stat:.4f}, p-value = {p:.4f}\")\n",
    "    if p < 0.05:\n",
    "        print(\"p-value < 0.05: Reject H₀, data is not normally distributed.\")\n",
    "    else:\n",
    "        print(\"p-value >= 0.05: Fail to reject H₀, data may be normally distributed.\")\n",
    "\n",
    "# Use Mann-Whitney U test since it’s the direct non-parametric equivalent of the t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mannwhitneyu\n",
    "from statsmodels.stats.multitest import multipletests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypothesis tests:\n",
    "# Test if web/catalog purchases negatively correlate with store purchases\n",
    "# Cannibalization requires store purchases to decrease when others increase\n",
    "# H0: High alternative channel users buy same/more in stores\n",
    "# H1: High alternative channel users buy LESS in stores (cannibalization)\n",
    "\n",
    "# high_web users equates to => df['NumWebPurchases'] > df['NumWebPurchases'].median()\n",
    "# high_catalog users equates to => df['NumCatalogPurchases'] > df['NumCatalogPurchases'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cannibalization looking at the medians:\n",
    "high_web = df_corr[df_corr[\"NumWebPurchases\"] > df_corr[\"NumWebPurchases\"].median()]\n",
    "low_web = df_corr[df_corr[\"NumWebPurchases\"] <= df_corr[\"NumWebPurchases\"].median()]\n",
    "\n",
    "high_catalog = df[df[\"NumCatalogPurchases\"] > df[\"NumCatalogPurchases\"].median()]\n",
    "low_catalog = df[df[\"NumCatalogPurchases\"] <= df[\"NumCatalogPurchases\"].median()]\n",
    "\n",
    "print(\"Web Cannibalization Test:\")\n",
    "print(\n",
    "    f\"High web users - median store purchases: {high_web['NumStorePurchases'].median()}\"\n",
    ")\n",
    "print(\n",
    "    f\"Low web users - median store purchases: {low_web['NumStorePurchases'].median()}\"\n",
    ")\n",
    "\n",
    "print(\"\\nCatalog Cannibalization Test:\")\n",
    "print(\n",
    "    f\"High catalog users - median store purchases: {high_catalog['NumStorePurchases'].median()}\"\n",
    ")\n",
    "print(\n",
    "    f\"Low catalog users - median store purchases: {low_catalog['NumStorePurchases'].median()}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cannibalization_analysis_with_adjustment(df):\n",
    "    \"\"\"Complete cannibalization analysis with multiple comparison correction\"\"\"\n",
    "\n",
    "    # What Each Column Represents:\n",
    "    # - Original_p: Raw p-values from Mann-Whitney tests (no correction)\n",
    "    # - Bonferroni_p: Traditional Bonferroni correction (p × number_of_tests)\n",
    "    # - Holm_p: Holm-Bonferroni correction (sequential method)\n",
    "    # - FDR_p: False Discovery Rate correction (Benjamini-Hochberg)\n",
    "\n",
    "    # Why You're Comparing All Methods: Different Conservative Levels:_\n",
    "    # - Most Conservative: Traditional Bonferroni\n",
    "    # - Moderate: Holm-Bonferroni\n",
    "    # - Least Conservative: FDR (Benjamini-Hochberg)\n",
    "\n",
    "    tests = {}\n",
    "    p_values = []\n",
    "    test_names = []\n",
    "\n",
    "    # Test 1: Web cannibalization\n",
    "    high_web = df[df[\"NumWebPurchases\"] > df[\"NumWebPurchases\"].median()]\n",
    "    low_web = df[df[\"NumWebPurchases\"] <= df[\"NumWebPurchases\"].median()]\n",
    "    stat1, p1 = mannwhitneyu(\n",
    "        high_web[\"NumStorePurchases\"], low_web[\"NumStorePurchases\"], alternative=\"less\"\n",
    "    )\n",
    "\n",
    "    tests[\"web_cannibalization\"] = {\n",
    "        \"statistic\": stat1,\n",
    "        \"p_value\": p1,\n",
    "        \"high_median\": high_web[\"NumStorePurchases\"].median(),\n",
    "        \"low_median\": low_web[\"NumStorePurchases\"].median(),\n",
    "    }\n",
    "    p_values.append(p1)\n",
    "    test_names.append(\"Web Cannibalization\")\n",
    "\n",
    "    # Test 2: Catalog cannibalization\n",
    "    high_catalog = df[df[\"NumCatalogPurchases\"] > df[\"NumCatalogPurchases\"].median()]\n",
    "    low_catalog = df[df[\"NumCatalogPurchases\"] <= df[\"NumCatalogPurchases\"].median()]\n",
    "    stat2, p2 = mannwhitneyu(\n",
    "        high_catalog[\"NumStorePurchases\"],\n",
    "        low_catalog[\"NumStorePurchases\"],\n",
    "        alternative=\"less\",\n",
    "    )\n",
    "\n",
    "    tests[\"catalog_cannibalization\"] = {\n",
    "        \"statistic\": stat2,\n",
    "        \"p_value\": p2,\n",
    "        \"high_median\": high_catalog[\"NumStorePurchases\"].median(),\n",
    "        \"low_median\": low_catalog[\"NumStorePurchases\"].median(),\n",
    "    }\n",
    "    p_values.append(p2)\n",
    "    test_names.append(\"Catalog Cannibalization\")\n",
    "\n",
    "    # Multiple comparison adjustments\n",
    "    bonferroni = [min(p * len(p_values), 1.0) for p in p_values]\n",
    "    _, holm_adj, _, _ = multipletests(p_values, method=\"holm\")\n",
    "    _, fdr_adj, _, _ = multipletests(p_values, method=\"fdr_bh\")\n",
    "\n",
    "    # Results summary\n",
    "    import pandas as pd\n",
    "\n",
    "    results_df = pd.DataFrame(\n",
    "        {\n",
    "            \"Test\": test_names,\n",
    "            \"Original_p\": p_values,\n",
    "            \"Bonferroni_p\": bonferroni,\n",
    "            \"Holm_p\": holm_adj,\n",
    "            \"FDR_p\": fdr_adj,\n",
    "            \"Significant_Original\": [p < 0.05 for p in p_values],\n",
    "            \"Significant_Bonferroni\": [p < 0.05 for p in bonferroni],\n",
    "            \"Significant_Holm\": [p < 0.05 for p in holm_adj],\n",
    "            \"Significant_FDR\": [p < 0.05 for p in fdr_adj],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # What do the results mean?\n",
    "    # - Significant = False means \"Fail to reject the null hypothesis\"\n",
    "    # - Significant = True means \"Reject the null hypothesis\"\n",
    "\n",
    "    return tests, results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the analysis\n",
    "tests, results = cannibalization_analysis_with_adjustment(df)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What do the results mean?\n",
    "# Significant = False means \"Fail to reject the null hypothesis\"\n",
    "# The data completely contradicts the cannibalization hypothesis. P Value can't be larger than 1.0\n",
    "\n",
    "# Multiple Comparison Results:\n",
    "# All adjustment methods (Bonferroni, Holm-Bonferroni, FDR) gave identical results, confirming that:\n",
    "# • Robust conclusion - findings hold under different statistical assumptions\n",
    "# • No need to worry about multiple testing - results are so clear that correction doesn’t matter\n",
    "\n",
    "# Conclusion\n",
    "# Testing for cannibalization was performed using multiple statistical approaches with different levels\n",
    "# of conservatism. Regardless of the correction method used (Bonferroni, Holm-Bonferroni, or FDR),\n",
    "# no evidence of cannibalization (all p-values = 1.0), providing strong evidence that alternative channels\n",
    "# complement rather than compete with store sales.\n",
    "\n",
    "# Final Interpretation\n",
    "# There is no statistical evidence that web or catalog purchases cannibalize store sales. In fact, customers\n",
    "# who purchase heavily through alternative channels also tend to be heavy store shoppers, suggesting these\n",
    "# channels work synergistically rather than competitively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4-SEZkZleCWN",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## d. US versus the rest of the world in total purchases per customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1756043834420,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "8BX-eOEVLT1-"
   },
   "outputs": [],
   "source": [
    "# d. US vs rest of world in total purchases per customer\n",
    "\n",
    "# Specify H₀ and H₁:\n",
    "# H₀: The distributions of Total_Puchases for US and non-US customers are\n",
    "#     identical (no difference in distribution).\n",
    "# H₁: The distribution of Total_Purchases for US customers is stochastically\n",
    "#     greater (US tends to have higher Total_Purchases for its customers).\n",
    "\n",
    "# Normality and Test Choice:\n",
    "# •  Use the t-test if Total_Puchases is approximately normally distributed.\n",
    "# •  Use the Mann-Whitney U test if the data is non-normal.\n",
    "\n",
    "# Interpreting Results:\n",
    "# •  P-value ≤ α (0.05): Reject H₀, concluding there is evidence that US has higher\n",
    "#    Total_Purchases for its customers than the rest of the world.\n",
    "# •  P-value > α: Fail to reject H₀, indicating insufficient evidence that US has higher\n",
    "#    Total_Purchases for its customers than the rest of the world."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 51,
     "status": "ok",
     "timestamp": 1756043834464,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "oAAxpFs0LT1-"
   },
   "outputs": [],
   "source": [
    "# Split data\n",
    "us_purchases = df[df['Country_US'] == 1]['Total_Purchases']\n",
    "non_us_purchases = df[df['Country_US'] == 0]['Total_Purchases']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1756043834544,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "fm3-2zV3LT1-",
    "outputId": "8d6fc5a5-fe35-41ba-91a5-18da12e1d905"
   },
   "outputs": [],
   "source": [
    "# Normality check\n",
    "from scipy.stats import shapiro\n",
    "\n",
    "# Purpose:\n",
    "# •  Tests the null hypothesis (H₀) that the data from the groups is normally distributed.\n",
    "# •  Alternative hypothesis (H₁): The data is not normally distributed.\n",
    "\n",
    "for group, data in [(1, us_purchases), (0, non_us_purchases)]:\n",
    "    stat, p = shapiro(data)\n",
    "    print(f\"Shapiro-Wilk Test for Country_US = {group}: p-value = {p:.4f}\")\n",
    "    if p < 0.05:\n",
    "        print(\"  p-value < 0.05: Reject H₀, data is not normally distributed.\")\n",
    "    else:\n",
    "        print(\"  p-value >= 0.05: Fail to reject H₀, data may be normally distributed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 67,
     "status": "ok",
     "timestamp": 1756043834628,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "tEFydBhnLT1-",
    "outputId": "626cb1e0-a90d-4a55-8e50-7a912efbbe29"
   },
   "outputs": [],
   "source": [
    "# Create a figure with two subplots side by side\n",
    "\n",
    "reset_plot_settings()\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6), sharey=True)\n",
    "\n",
    "# Boxplot\n",
    "sns.boxplot(\n",
    "    x=\"Country_US\", y=\"Total_Purchases\", data=df, ax=ax1, hue=\"Country_US\", legend=False\n",
    ")\n",
    "ax1.set_title(\"Box Plot of Total Purchases for US and Non-US Customers\", fontsize=12)\n",
    "ax1.set_ylabel(\"Total Purchases\", fontsize=12)\n",
    "ax1.set_xlabel(\"Country\", fontsize=12)\n",
    "ax1.set_xticks([0, 1], [\"Not USA\", \"USA\"])\n",
    "ax1.grid(True, axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "# Violin Plot\n",
    "sns.violinplot(\n",
    "    x=\"Country_US\", data=df, y=\"Total_Purchases\", legend=False, ax=ax2, hue=\"Country_US\"\n",
    ")\n",
    "ax2.set_title(\"Violin Plot of Total Purchases for US and Non-US Customers\", fontsize=12)\n",
    "ax2.set_xlabel(\"Country\", fontsize=12)\n",
    "ax2.set_xticks([0, 1], [\"Not USA\", \"USA\"])\n",
    "ax2.grid(True, axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Descriptive Statistics\n",
    "current_stats = df.groupby('Country_US')['Total_Purchases'].agg(['mean','median','std','count'])\n",
    "print(current_stats)\n",
    "\n",
    "# Shapiro-Wilk test and plots show data is not normally distributed so a non-parametric\n",
    "# test seems more appropriate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1756043834678,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "89jHxilkLT1_",
    "outputId": "c7cd72dd-b36b-43ed-ce9d-93805fc19155"
   },
   "outputs": [],
   "source": [
    "# Perform Mann-Whitney U Test (One-Tailed)\n",
    "# H₀: The distributions of Total_Puchases for US and non-US customers are\n",
    "#     identical (no difference in distribution).\n",
    "# H₁: The distribution of Total_Purchases for US customers is stochastically\n",
    "#     greater (US tends to have higher Total_Purchases for its customers).\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "stat, p_value = mannwhitneyu(us_purchases, non_us_purchases, alternative=\"greater\")\n",
    "print(f\"Mann-Whitney U Test: statistic = {stat:.4f}, p-value = {p_value:.4f}\")\n",
    "\n",
    "# Interpretation\n",
    "alpha = 0.05\n",
    "if p_value <= alpha:\n",
    "    print(\n",
    "        \"Reject H₀: Reject H₀, concluding there is evidence that US has higher Total_Purchases for its customers than the rest of the world.\"\n",
    "    )\n",
    "else:\n",
    "    print(\n",
    "        \"Fail to reject H₀: No evidence that US has higher Total_Purchases for its customers than the rest of the world.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1756043834737,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "x6VKYEqrLT1_",
    "outputId": "fad7e5f5-d208-46a4-a1ec-00503f469e41"
   },
   "outputs": [],
   "source": [
    "# Why a t-test may be ok\n",
    "# Large sample sizes (e.g., n > 30 or ideally n > 50 per group), due to the Central Limit Theorem (CLT).\n",
    "# The CLT states that the sampling distribution of the mean approaches normality as sample size increases,\n",
    "# even if the underlying data is non-normal.\n",
    "\n",
    "print(f\"Sample size for Country:\\n{df['Country_US'].value_counts()}\")\n",
    "# Sample Size is Large: Both groups (Country_US = 1 and 0) have n > 50\n",
    "# the CLT helps ensure the t-test is robust."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1756043834787,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "3tqeFgo3LT1_",
    "outputId": "8253e262-9222-47c5-cb82-9c99e4bc3975"
   },
   "outputs": [],
   "source": [
    "# Perform Levene's test\n",
    "\n",
    "# Purpose:\n",
    "# •  Tests the null hypothesis (H₀) that the variances of the groups are equal.\n",
    "# •  Alternative hypothesis (H₁): The variances are not equal.\n",
    "\n",
    "# Variations of test:\n",
    "# •  Standard Levene’s Test: Uses the group mean for calculating deviations.\n",
    "# •  Modified Levene’s Test (Brown-Forsythe): Uses the group median instead of the mean,\n",
    "#    which is more robust to non-normal data.\n",
    "\n",
    "# Implications of test:\n",
    "# •  If Levene’s test indicates unequal variances (p-value ≤ 0.05), use Welch’s t-test to compare means.\n",
    "# •  If variances are equal, use the standard t-test.\n",
    "\n",
    "from scipy.stats import levene\n",
    "alpha = 0.05\n",
    "\n",
    "stat, p_levene = levene(us_purchases, non_us_purchases, center='median')\n",
    "print(f\"\\nLevene's Test: statistic = {stat:.4f}, p-value = {p_levene:.4f}\")\n",
    "print(f\"{'Unequal variances' if p_levene < alpha else 'Equal variances'} (p {'<' if p_levene < alpha else '>='} {alpha})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 90,
     "status": "ok",
     "timestamp": 1756043834898,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "BkpIfWP2LT1_",
    "outputId": "054437c1-e622-4818-cb7d-6092b3510685"
   },
   "outputs": [],
   "source": [
    "# Run standard parametric t-test since variances are equal\n",
    "\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "print(\"\\nStandard t-Test:\")\n",
    "stat, p_ttest = ttest_ind(\n",
    "    us_purchases, non_us_purchases, alternative=\"greater\", equal_var=True\n",
    ")\n",
    "print(f\"t-test: statistic = {stat:.4f}, p-value = {p_ttest:.4f}\")\n",
    "\n",
    "if p_ttest <= alpha:\n",
    "    print(\n",
    "        \"Reject H₀: Reject H₀, concluding there is evidence that US has higher Total_Purchases for its customers than the rest of the world.\"\n",
    "    )\n",
    "else:\n",
    "    print(\n",
    "        \"Fail to reject H₀: No evidence that US has higher Total_Purchases for its customers than the rest of the world.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 59,
     "status": "ok",
     "timestamp": 1756043834899,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "9vfcypi-LT1_"
   },
   "outputs": [],
   "source": [
    "# Conclusion\n",
    "# Both the parametric test (Standard t-Test) and the non-parametric test (Mann-Whitney U Test)\n",
    "# fail to reject H₀, meaning there is no evidence that Total_Purchases for US customers is greater than Total_Purchases for Non US Customers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-oFS5q6jgAfx"
   },
   "source": [
    "# Step 8: Additional Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VCZRsaNXeSPe",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## a. Identify the top-performing products and those with the lowest revenue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 441,
     "status": "ok",
     "timestamp": 1756043835308,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "QH-5o8KqLT2A",
    "outputId": "85a8a8bc-5cc7-41a6-bdc7-d0b9cd3d8faf"
   },
   "outputs": [],
   "source": [
    "# a. Identify the top-performing products and those with the lowest revenue\n",
    "\n",
    "# Calculate total revenue for each product\n",
    "product_revenue = df[\n",
    "    [\n",
    "        \"MntWines\",\n",
    "        \"MntFruits\",\n",
    "        \"MntMeatProducts\",\n",
    "        \"MntFishProducts\",\n",
    "        \"MntSweetProducts\",\n",
    "        \"MntGoldProds\",\n",
    "    ]\n",
    "].sum()\n",
    "\n",
    "reset_plot_settings()\n",
    "\n",
    "# Create bar plot showing revenue\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "product_revenue.sort_values(ascending=False).plot(\n",
    "    kind=\"bar\", color=[\"#1f77b4\", \"#ff7f0e\", \"#2ca02c\", \"#d62728\", \"#9467bd\", \"#8c564b\"]\n",
    ")\n",
    "\n",
    "plt.title(\"Total Revenue by Product Category\")\n",
    "plt.xlabel(\"Product Category\")\n",
    "plt.ylabel(\"Total Revenue ($)\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 78,
     "status": "ok",
     "timestamp": 1756043835310,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "Zid8BBN3LT2A",
    "outputId": "1ebb7a64-e738-4d95-be31-b424fde56360"
   },
   "outputs": [],
   "source": [
    "# Print top and bottom products\n",
    "print(\"Top-performing products:\")\n",
    "print(product_revenue.sort_values(ascending=False).head(3))\n",
    "print(\"\\nLowest-performing products:\")\n",
    "print(product_revenue.sort_values(ascending=True).head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-pVYV4Ja0Y8w"
   },
   "source": [
    "### Results\n",
    "Top-performing products:\n",
    "- MntWines           679826\n",
    "- MntMeatProducts    368418\n",
    "- MntGoldProds        98328\n",
    "\n",
    "Lowest-performing products:\n",
    "- MntFruits           58731\n",
    "- MntSweetProducts    60543\n",
    "- MntFishProducts     83905"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wgFBL7MPeYAr",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## b. Examine if there is a correlation between customers’ age and the acceptance rate of the last campaign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 121,
     "status": "ok",
     "timestamp": 1756043835377,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "mSqnYSwSLT2A",
    "outputId": "bbfa40ee-3773-48f5-a754-098d8209c6c2"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import pointbiserialr\n",
    "\n",
    "corr, p_value = pointbiserialr(df[\"Age\"], df[\"Response\"])\n",
    "print(\n",
    "    f\"Point-Biserial Correlation between Age and Response: {corr:.3f} (p-value: {p_value:.3f})\"\n",
    ")\n",
    "\n",
    "# What is Point-Biserial Correlation?\n",
    "# Point-biserial correlation is chosen because it is a statistical measure that quantifies\n",
    "# the linear relationship between a continuous variable and a binary variable.\n",
    "# It's essentially a special case of the standard Pearson correlation coefficient,\n",
    "# specifically designed for binary outcomes.\n",
    "\n",
    "# Why I used\n",
    "# In campaign analysis, you have:\n",
    "# - Binary variable: Campaign response (Accepted = 1, Not Accepted = 0)\n",
    "# - Continuous variable: Age (ranging from ~30 to 80+)\n",
    "\n",
    "# Output: correlation ≈ -0.019, p-value ≈ 0.372, indicating a very weak, non-significant\n",
    "# relationship. Younger customers may have a slight tendency to accept the campaign,\n",
    "# but the effect is negligible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 56,
     "status": "ok",
     "timestamp": 1756043835378,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "BdrmHbKULT2A",
    "outputId": "d827ea25-48f4-4fed-9c9d-b5f9ba7fa7cb"
   },
   "outputs": [],
   "source": [
    "# Statistics to use for age analysis for last campaign response\n",
    "# Data will be used in plots\n",
    "\n",
    "accepted = df[df[\"Response\"] == 1][\"Age\"]\n",
    "not_accepted = df[df[\"Response\"] == 0][\"Age\"]\n",
    "\n",
    "# Create age groups\n",
    "bins = [0, 40, 50, 60, 70, 100]\n",
    "labels = [\"<40\", \"40-50\", \"50-60\", \"60-70\", \"70+\"]\n",
    "df[\"Age_Group\"] = pd.cut(df[\"Age\"], bins=bins, labels=labels, include_lowest=True)\n",
    "print(df[\"Age_Group\"].value_counts())\n",
    "\n",
    "age_analysis = (\n",
    "    df.groupby(\"Age_Group\")\n",
    "    .agg({\"Response\": [\"sum\", \"count\", \"mean\"], \"Age\": [\"mean\", \"std\"]})\n",
    "    .round(3)\n",
    ")\n",
    "\n",
    "age_analysis.columns = [\n",
    "    \"Accepted_Count\",\n",
    "    \"Total_Count\",\n",
    "    \"Acceptance_Rate\",\n",
    "    \"Mean_Age\",\n",
    "    \"Age_SD\",\n",
    "]\n",
    "age_analysis[\"Sample_Size_Category\"] = pd.qcut(\n",
    "    age_analysis[\"Total_Count\"], q=3, labels=[\"Small\", \"Medium\", \"Large\"]\n",
    ")\n",
    "print(age_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 230,
     "status": "ok",
     "timestamp": 1756043835579,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "o50aEOAmLT2B",
    "outputId": "a58c94f7-c340-4c69-d390-16e6104237d1"
   },
   "outputs": [],
   "source": [
    "# Visualizations\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "reset_plot_settings()\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# Define colors upfront\n",
    "# Use matplotlib's palette\n",
    "sns.set_palette(\"tab10\")\n",
    "matplot_colors = sns.color_palette(\"tab10\")\n",
    "matplot_blue = matplot_colors[0]\n",
    "matplot_orange = matplot_colors[1]\n",
    "\n",
    "# Age group acceptance rates\n",
    "acceptance_rates = age_analysis[\"Acceptance_Rate\"]\n",
    "sample_sizes = age_analysis[\"Total_Count\"]\n",
    "\n",
    "# Box Plot with statistical results\n",
    "sns.boxplot(\n",
    "    x=\"Response\",\n",
    "    y=\"Age\",\n",
    "    data=df,\n",
    "    hue=\"Response\",\n",
    "    ax=ax1,\n",
    "    palette=\"tab10\",\n",
    "    legend=False,\n",
    ")\n",
    "ax1.set_xlabel(\"Response\")\n",
    "ax1.set_xticks([0, 1], [\"Not Accepted\", \"Accepted\"])\n",
    "ax1.set_title(\"Age Distribution Box Plot\")\n",
    "ax1.set_ylabel(\"Age\")\n",
    "\n",
    "# Distribution comparison with statistical annotation\n",
    "# Create subsets\n",
    "not_accepted = df[df[\"Response\"] == 0][\"Age\"]\n",
    "accepted = df[df[\"Response\"] == 1][\"Age\"]\n",
    "\n",
    "# Create labels with counts\n",
    "df[\"Response_Label\"] = df[\"Response\"].map(\n",
    "    {0: f\"Not Accepted (n={len(not_accepted)})\", 1: f\"Accepted (n={len(accepted)})\"}\n",
    ")\n",
    "\n",
    "# Create histogram with specific colors\n",
    "sns.histplot(\n",
    "    data=df,\n",
    "    x=\"Age\",\n",
    "    hue=\"Response_Label\",\n",
    "    kde=True,\n",
    "    stat=\"density\",\n",
    "    ax=ax2,\n",
    "    alpha=0.6,\n",
    "    hue_order=[\n",
    "        f\"Not Accepted (n={len(not_accepted)})\",\n",
    "        f\"Accepted (n={len(accepted)})\",\n",
    "    ],\n",
    "    palette=\"tab10\",\n",
    "    legend=False,\n",
    ")\n",
    "\n",
    "# Add mean lines with matching colors\n",
    "ax2.axvline(not_accepted.mean(), color=matplot_blue, linestyle=\"--\", alpha=0.8)\n",
    "ax2.axvline(accepted.mean(), color=matplot_orange, linestyle=\"--\", alpha=0.8)\n",
    "\n",
    "# Create legend manually\n",
    "legend_elements = [\n",
    "    Patch(\n",
    "        facecolor=matplot_blue, alpha=0.6, label=f\"Not Accepted (n={len(not_accepted)})\"\n",
    "    ),\n",
    "    Patch(facecolor=matplot_orange, alpha=0.6, label=f\"Accepted (n={len(accepted)})\"),\n",
    "    Line2D(\n",
    "        [0],\n",
    "        [0],\n",
    "        color=matplot_blue,\n",
    "        linestyle=\"--\",\n",
    "        alpha=0.8,\n",
    "        label=f\"Mean Not Accepted: {not_accepted.mean():.1f}\",\n",
    "    ),\n",
    "    Line2D(\n",
    "        [0],\n",
    "        [0],\n",
    "        color=matplot_orange,\n",
    "        linestyle=\"--\",\n",
    "        alpha=0.8,\n",
    "        label=f\"Mean Accepted: {accepted.mean():.1f}\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "ax2.legend(handles=legend_elements)\n",
    "\n",
    "# Set titles and labels\n",
    "ax2.set_title(\n",
    "    f\"Age Distribution by Campaign Response\\n\"\n",
    "    f\"Mean Difference: {accepted.mean() - not_accepted.mean():.2f} years\"\n",
    ")\n",
    "ax2.set_xlabel(\"Age\")\n",
    "ax2.set_ylabel(\"Density\")\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1756043835609,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "h92GmizniGAi"
   },
   "outputs": [],
   "source": [
    "# Results and possible conclusions from intial visualizations show that age does\n",
    "# not seem to be correlated strongly to age. This is based on the point-biserial\n",
    "# correlation and the boxplots and histogram plots which show if anything\n",
    "# younger customers have a slight tendency to accept the campaign.\n",
    "\n",
    "# Below several other visualizations are created to explore the age versus\n",
    "# campaign response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 138,
     "status": "ok",
     "timestamp": 1756043835781,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "fb0sRcpnLT2B",
    "outputId": "604af764-47f8-47c6-8b2e-a038ca32575b"
   },
   "outputs": [],
   "source": [
    "reset_plot_settings()\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6), sharey=True)\n",
    "\n",
    "# Bar plot of acceptance rates\n",
    "# Age group acceptance rates with confidence intervals\n",
    "acceptance_rates = age_analysis[\"Acceptance_Rate\"]\n",
    "sample_sizes = age_analysis[\"Total_Count\"]\n",
    "\n",
    "# Calculate 95% confidence intervals for proportions\n",
    "z_score = 1.96  # 95% confidence\n",
    "ci_lower = []\n",
    "ci_upper = []\n",
    "\n",
    "for rate, n in zip(acceptance_rates, sample_sizes):\n",
    "    se = np.sqrt(rate * (1 - rate) / n)  # Standard error for proportion\n",
    "    ci_lower.append(max(0, rate - z_score * se))\n",
    "    ci_upper.append(min(1, rate + z_score * se))\n",
    "\n",
    "# print(age_analysis[['Age_Group','Acceptance_Rate','Total_Count']])\n",
    "print(age_analysis)\n",
    "\n",
    "bars = sns.barplot(\n",
    "    x=\"Age_Group\",\n",
    "    y=\"Acceptance_Rate\",\n",
    "    data=age_analysis,\n",
    "    errorbar=None,\n",
    "    color=matplot_orange,\n",
    "    ax=ax1,\n",
    ")\n",
    "ax1.errorbar(\n",
    "    x=range(len(acceptance_rates)),\n",
    "    y=acceptance_rates,\n",
    "    yerr=[acceptance_rates - ci_lower, ci_upper - acceptance_rates],\n",
    "    fmt=\"none\",\n",
    "    c=\"black\",\n",
    "    capsize=5,\n",
    ")\n",
    "for i, bar in enumerate(bars.patches):\n",
    "    height = bar.get_height()\n",
    "    ax1.text(\n",
    "        bar.get_x() + bar.get_width() / 2,\n",
    "        height - 0.1,\n",
    "        f\"Acceptance\\nRate\\n{(age_analysis['Acceptance_Rate'].iloc[i]) * 100}%\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontsize=\"small\",\n",
    "    )\n",
    "ax1.set_title(\n",
    "    f\"Acceptance Rate of Last Campaign by Age Group (Correlation: {corr:.3f})\",\n",
    "    fontsize=12,\n",
    ")\n",
    "ax1.set_xlabel(\"Age Group\", fontsize=12)\n",
    "ax1.set_ylabel(\"Acceptance Rate (Proportion Accepted)\", fontsize=12)\n",
    "ax1.grid(True, axis=\"y\", alpha=0.3)\n",
    "ax1.set_axisbelow(True)\n",
    "ax1.set_ylim(0, max(ci_upper) * 1.1)\n",
    "\n",
    "\n",
    "# Scatterplot showing age group sample size and acceptance rate\n",
    "age_analysis_reset = age_analysis.reset_index()\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=age_analysis_reset,\n",
    "    x=\"Total_Count\",\n",
    "    y=\"Acceptance_Rate\",\n",
    "    hue=\"Age_Group\",\n",
    "    s=100,\n",
    "    alpha=0.7,\n",
    "    ax=ax2,\n",
    "    palette=\"viridis\",\n",
    ")\n",
    "\n",
    "# Add annotations\n",
    "for i, row in age_analysis_reset.iterrows():\n",
    "    ax2.annotate(\n",
    "        row[\"Age_Group\"],\n",
    "        (row[\"Total_Count\"], row[\"Acceptance_Rate\"]),\n",
    "        xytext=(-8, 8),\n",
    "        textcoords=\"offset points\",\n",
    "        fontsize=9,\n",
    "    )\n",
    "\n",
    "ax2.set_xlabel(\"Sample Size\", fontsize=12)\n",
    "ax2.set_ylabel(\"Acceptance Rate\", fontsize=12)\n",
    "ax2.set_title(\n",
    "    \"Sample Size vs Acceptance Rate by Age Group\\n(Larger samples = more reliable estimates)\",\n",
    "    fontsize=12,\n",
    ")\n",
    "ax2.grid(True, axis=\"y\", alpha=0.3)\n",
    "ax2.set_axisbelow(True)\n",
    "ax2.legend(title=\"Age Group\", loc=\"upper right\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 487,
     "status": "ok",
     "timestamp": 1756043836293,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "y1l9CLuyocbE",
    "outputId": "c731f6af-53bc-4ae7-da87-dd1cab9a1046"
   },
   "outputs": [],
   "source": [
    "# Cleanup and summary analysis creation\n",
    "df.drop(\"Response_Label\", axis=1, inplace=True)\n",
    "age_analysis_reset = age_analysis.copy()\n",
    "age_analysis_reset[\"Acceptance_Rate_Percent\"] = (\n",
    "    age_analysis_reset[\"Acceptance_Rate\"] * 100\n",
    ")\n",
    "print(age_analysis_reset[[\"Sample_Size_Category\", \"Acceptance_Rate_Percent\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 403,
     "status": "ok",
     "timestamp": 1756043836295,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "ZT0nWsITiS7a"
   },
   "outputs": [],
   "source": [
    "# Output: correlation, boxplots, histogram plots, bar plot with error bars and scatter\n",
    "# plot show no significant age to campaign acceptance relationship\n",
    "\n",
    "# Primary Findings\n",
    "# •  Minimal Age Effect: The most striking finding is that age has virtually no meaningful\n",
    "#    relationship with campaign acceptance. The correlation of -0.019 is essentially zero,\n",
    "#    indicating no practical relationship between age and response rates (very weak,\n",
    "#    non-significant relationship).\n",
    "# •  Consistent Acceptance Across Age Groups: The acceptance rates across all age groups\n",
    "#    cluster between 13-16%, with the 60-70 age group showing the lowest rate at approximately\n",
    "#    13% and the <40 and 70+ groups showing the highest at around 16%. This 3\n",
    "#    percentage point difference is quite small from a practical standpoint.\n",
    "\n",
    "# Statistical Considerations\n",
    "# •  Sample Size Reliability: The scatterplot reveals that the 60-70 age group has the\n",
    "#    smallest sample size (467), while the 50-60 group has the largest (674).\n",
    "#    The smaller sample size for the 60-70 group may contribute to the slightly lower observed\n",
    "#    acceptance rate, but the confidence intervals shown in the bar chart suggest these\n",
    "#    differences aren't statistically significant.\n",
    "# •  Age Distribution Insights: The first chart shows that both accepted and non-accepted\n",
    "#    groups have very similar age distributions, with mean ages differing by only 0.62 years\n",
    "#    (56.2 vs 55.6). This minimal difference reinforces that age is not a meaningful predictor.\n",
    "\n",
    "# Result\n",
    "# Campaign acceptance does not seem to be correlated strongly to age."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2LPkZ9YtmPoH",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## c. Determine the country with the highest number of customers who accepted the last campaign."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 397,
     "status": "ok",
     "timestamp": 1756043836313,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "B6xfQv4cLT2B",
    "outputId": "872f91f4-6d2d-4bea-d1ec-24cacf69c3d2"
   },
   "outputs": [],
   "source": [
    "# Define country columns (dummy-encoded)\n",
    "\n",
    "country_columns = [\n",
    "    \"Country_AUS\",\n",
    "    \"Country_CA\",\n",
    "    \"Country_GER\",\n",
    "    \"Country_IND\",\n",
    "    \"Country_ME\",\n",
    "    \"Country_SA\",\n",
    "    \"Country_SP\",\n",
    "    \"Country_US\",\n",
    "]\n",
    "\n",
    "# Verify country columns exist\n",
    "\n",
    "missing_cols = [col for col in country_columns if col not in df.columns]\n",
    "if missing_cols:\n",
    "    print(f\"Warning: Missing country columns: {missing_cols}\")\n",
    "    country_columns = [col for col in country_columns if col in df.columns]\n",
    "\n",
    "print(\"Available country columns:\", country_columns)\n",
    "\n",
    "# Display basic information about the dataset\n",
    "\n",
    "print(\"\\nDataset Overview:\")\n",
    "print(f\"Total customers: {len(df):,}\")\n",
    "print(f\"Total countries: {len(country_columns)}\")\n",
    "print(f\"Customers who accepted last campaign: {df['Response'].sum():,}\")\n",
    "print(f\"Overall acceptance rate: {(df['Response'].sum() / len(df) * 100):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 79,
     "status": "ok",
     "timestamp": 1756043836350,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "wYot_15SLT2C"
   },
   "outputs": [],
   "source": [
    "# Calculate key metrics by country using dummy columns\n",
    "\n",
    "country_stats = []\n",
    "\n",
    "for country_col in country_columns:\n",
    "    # Extract country name from column (remove ‘Country_’ prefix)\n",
    "    country_name = country_col.replace(\"Country_\", \"\")\n",
    "\n",
    "    # Filter customers from this country (where dummy variable = 1)\n",
    "    country_customers = df[df[country_col] == 1]\n",
    "\n",
    "    if len(country_customers) > 0:\n",
    "        total_customers = len(country_customers)\n",
    "        accepted_customers = country_customers[\"Response\"].sum()\n",
    "        acceptance_rate = (accepted_customers / total_customers) * 100\n",
    "\n",
    "        country_stats.append(\n",
    "            {\n",
    "                \"Country\": country_name,\n",
    "                \"Total_Customers\": total_customers,\n",
    "                \"Accepted_Customers\": accepted_customers,\n",
    "                \"Acceptance_Rate\": acceptance_rate,\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 49,
     "status": "ok",
     "timestamp": 1756043836375,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "3VXCDjJ2LT2C"
   },
   "outputs": [],
   "source": [
    "# Convert to DataFrame\n",
    "\n",
    "country_stats = pd.DataFrame(country_stats)\n",
    "country_stats = country_stats.sort_values(\"Accepted_Customers\", ascending=False)\n",
    "country_stats = country_stats.reset_index(drop=True)\n",
    "# print(country_stats.columns)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COUNTRY PERFORMANCE SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "country_stats_perf = country_stats.copy()\n",
    "country_stats_perf = country_stats_perf.set_index(\"Country\")\n",
    "print(country_stats_perf.round(2))\n",
    "\n",
    "# Find the answer to our main question\n",
    "top_count = int(country_stats[\"Accepted_Customers\"].max())\n",
    "stat_count = country_stats[country_stats[\"Accepted_Customers\"] == top_count]\n",
    "top_country = stat_count[\"Country\"].iloc[0]\n",
    "top_rate = country_stats[\"Acceptance_Rate\"].max()\n",
    "stat_rate = country_stats[country_stats[\"Acceptance_Rate\"] == top_rate]\n",
    "top_rate_country = stat_rate[\"Country\"].iloc[0]\n",
    "\n",
    "# print(top_count)\n",
    "# print(top_rate)\n",
    "# print(country_stats[country_stats['Acceptance_Rate']== top_rate])\n",
    "# stat1 = country_stats[country_stats['Accepted_Customers']== top_count]\n",
    "# print(stat_rate['Total_Customers'].iloc[0])\n",
    "\n",
    "\n",
    "print(f\"\\n{top_country} has the highest number of customers ({top_count}) who accepted the last campaign\")\n",
    "print(f\"{top_country}'s acceptance rate for the last campaign was {round(stat_count['Acceptance_Rate'].iloc[0],3)}%\")\n",
    "print(f\"{top_rate_country} has the highest acceptance rate ({round(top_rate,3)}%) for the last campaign\")\n",
    "print(f\"However the total number of {top_rate_country} customers ({stat_rate['Total_Customers'].iloc[0]})\\\n",
    "# and the number of {top_rate_country} customers that accepted ({stat_rate['Accepted_Customers'].iloc[0]}) are low.\")\n",
    "print(f\"In comparison the total number of {top_country} customers ({stat_count['Total_Customers'].iloc[0]})\\\n",
    "# and the number of {top_country} customers that accepted ({stat_count['Accepted_Customers'].iloc[0]}) are much higher.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 56,
     "status": "ok",
     "timestamp": 1756043836398,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "sNZdbsUSHF2n",
    "outputId": "4d3357d4-0c06-4bd3-fb6d-eb1821b973b9"
   },
   "outputs": [],
   "source": [
    "print(country_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizations\n",
    "\n",
    "# Set the style for better-looking plots\n",
    "reset_plot_settings()\n",
    "\n",
    "plt.style.use(\"default\")\n",
    "# sns.set_palette('husl')\n",
    "sns.set_context(\"notebook\", font_scale=1.1)\n",
    "\n",
    "# 2x2 grid\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "plt.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "\n",
    "# 1. Main Answer: Bar plot of customers who accepted by country\n",
    "sns.barplot(\n",
    "    data=country_stats.reset_index(),\n",
    "    x=\"Country\",\n",
    "    y=\"Accepted_Customers\",\n",
    "    ax=ax1,\n",
    "    palette=\"viridis\",\n",
    ")\n",
    "ax1.set_title(\"Customers Who Accepted Last Campaign by Country\", fontsize=14, pad=20)\n",
    "ax1.set_ylabel(\"Number of Customers Who Accepted\", fontsize=12)\n",
    "ax1.set_xlabel(\"Country\", fontsize=12)\n",
    "ax1.grid(True, axis=\"y\", alpha=0.3)\n",
    "ax1.set_axisbelow(True)\n",
    "\n",
    "# Highlight the top country with a different color and annotation\n",
    "bars = ax1.patches\n",
    "max_height = max([bar.get_height() for bar in bars])\n",
    "bars[0].set_color(\"#FF6B6B\")  # Highlight top country in red\n",
    "bars[0].set_edgecolor(\"black\")\n",
    "bars[0].set_linewidth(2)\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, bar in enumerate(bars):\n",
    "    height = bar.get_height()\n",
    "    ax1.text(\n",
    "        bar.get_x() + bar.get_width() / 2.0,\n",
    "        height,\n",
    "        f\"{int(height)}\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontsize=10,\n",
    "    )\n",
    "\n",
    "\n",
    "# 2. Total customers by country (context)\n",
    "sns.barplot(\n",
    "    data=country_stats.reset_index(),\n",
    "    x=\"Country\",\n",
    "    y=\"Total_Customers\",\n",
    "    ax=ax2,\n",
    "    palette=\"coolwarm\",\n",
    ")\n",
    "ax2.set_title(\"Total Customer Base by Country\", fontsize=14, pad=20)\n",
    "ax2.set_ylabel(\"Total Number of Customers\", fontsize=12)\n",
    "ax2.set_xlabel(\"Country\", fontsize=12)\n",
    "ax2.grid(True, axis=\"y\", alpha=0.3)\n",
    "ax2.set_axisbelow(True)\n",
    "\n",
    "# Add value labels\n",
    "for i, bar in enumerate(ax2.patches):\n",
    "    height = bar.get_height()\n",
    "    ax2.text(\n",
    "        bar.get_x() + bar.get_width() / 2.0,\n",
    "        height,\n",
    "        f\"{int(height)}\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontsize=10,\n",
    "    )\n",
    "\n",
    "# 3. Acceptance rates by country\n",
    "sns.barplot(\n",
    "    data=country_stats.reset_index(),\n",
    "    x=\"Country\",\n",
    "    y=\"Acceptance_Rate\",\n",
    "    ax=ax3,\n",
    "    palette=\"RdYlBu_r\",\n",
    ")\n",
    "ax3.set_title(\"Acceptance Rate by Country\", fontsize=14, pad=20)\n",
    "ax3.set_ylabel(\"Acceptance Rate (%)\", fontsize=12)\n",
    "ax3.set_xlabel(\"Country\", fontsize=12)\n",
    "\n",
    "# Add percentage labels\n",
    "for i, bar in enumerate(ax3.patches):\n",
    "    height = bar.get_height()\n",
    "    ax3.text(\n",
    "        bar.get_x() + bar.get_width() / 2.0,\n",
    "        height + 0.3,\n",
    "        f\"{height:.1f}%\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontsize=\"10\",\n",
    "    )\n",
    "ax3.grid(True, axis=\"y\", alpha=0.3)\n",
    "ax3.set_axisbelow(True)\n",
    "\n",
    "# 4. Scatter plot: Total customers vs Accepted customers\n",
    "# Create scatter plot with country data\n",
    "scatter = sns.scatterplot(\n",
    "    data=country_stats,\n",
    "    x=\"Total_Customers\",\n",
    "    y=\"Accepted_Customers\",\n",
    "    hue=\"Acceptance_Rate\",\n",
    "    hue_norm=(0, 100),  # Set color scale from 0-100%\n",
    "    s=150,\n",
    "    alpha=0.8,\n",
    "    ax=ax4,\n",
    "    palette=\"plasma\",\n",
    "    legend=False,\n",
    ")\n",
    "\n",
    "# Selective labeling - Label outliers or extreme values\n",
    "high_acceptance = country_stats[\"Acceptance_Rate\"] > country_stats[\n",
    "    \"Acceptance_Rate\"\n",
    "].quantile(0.75)\n",
    "low_acceptance = country_stats[\"Acceptance_Rate\"] < country_stats[\n",
    "    \"Acceptance_Rate\"\n",
    "].quantile(0.25)\n",
    "high_customers = country_stats[\"Total_Customers\"] > country_stats[\n",
    "    \"Total_Customers\"\n",
    "].quantile(0.75)\n",
    "\n",
    "for idx, row in country_stats.iterrows():\n",
    "    if (\n",
    "        high_acceptance.iloc[idx]\n",
    "        or low_acceptance.iloc[idx]\n",
    "        or high_customers.iloc[idx]\n",
    "    ):\n",
    "        ax4.annotate(\n",
    "            row[\"Country\"],\n",
    "            xy=(row[\"Total_Customers\"], row[\"Accepted_Customers\"]),\n",
    "            xytext=(5, 5),\n",
    "            textcoords=\"offset points\",\n",
    "            fontsize=9,\n",
    "            alpha=0.8,\n",
    "            ha=\"left\",  # horizontal alignment\n",
    "            va=\"bottom\",\n",
    "        )  # vertical alignment\n",
    "\n",
    "# Add colorbar/legend for acceptance rate\n",
    "norm = plt.Normalize(vmin=0, vmax=100)\n",
    "sm = plt.cm.ScalarMappable(cmap=\"plasma\", norm=norm)\n",
    "sm.set_array([])\n",
    "cbar = plt.colorbar(sm, ax=ax4)\n",
    "cbar.set_label(\"Acceptance Rate (%)\", fontsize=11)\n",
    "\n",
    "# Set plot titles and labels\n",
    "ax4.set_title(\"Customer Base vs Campaign Acceptance by Country\", fontsize=14, pad=20)\n",
    "ax4.set_xlabel(\"Total Customer Base\", fontsize=12)\n",
    "ax4.set_ylabel(\"Customers Who Accepted\", fontsize=12)\n",
    "\n",
    "# Add grid for better readability\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 46,
     "status": "ok",
     "timestamp": 1756043837871,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "wEUS_PJSLT2C",
    "outputId": "147ce216-aed0-4b98-ea67-e86f62423a02"
   },
   "outputs": [],
   "source": [
    "# Summary statistics table\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DETAILED INSIGHTS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Create a more detailed summary\n",
    "\n",
    "detailed_stats = country_stats.copy()\n",
    "detailed_stats[\"Market_Share_Total\"] = (\n",
    "    detailed_stats[\"Total_Customers\"] / len(df) * 100\n",
    ").round(1)\n",
    "detailed_stats[\"Market_Share_Accepted\"] = (\n",
    "    detailed_stats[\"Accepted_Customers\"] / df[\"Response\"].sum() * 100\n",
    ").round(1)\n",
    "\n",
    "detailed_stats = detailed_stats.rename(\n",
    "    columns={\"Accepted_Customers\": \"Customers_Accepted\"}\n",
    ")\n",
    "\n",
    "# Set the 'Country' column as the index\n",
    "detailed_stats = detailed_stats.set_index(\"Country\")\n",
    "\n",
    "print(round(detailed_stats, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 45,
     "status": "ok",
     "timestamp": 1756043837892,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "y8m6McP6LT2C"
   },
   "outputs": [],
   "source": [
    "# Key insights\n",
    "total_accepted = df[\"Response\"].sum()\n",
    "print('\\nKEY INSIGHTS:')\n",
    "print(f'• {top_country} leads with {top_count} customers accepting the campaign ({(top_count/total_accepted*100):.1f}% of all acceptances)')\n",
    "print(f\"• {top_country} has {int(detailed_stats.loc[top_country, 'Total_Customers'])} total customers ({detailed_stats.loc[top_country, 'Market_Share_Total']:.1f}% of customer base)\")\n",
    "print(f\"• {top_country}’s acceptance rate for the last campaign is {detailed_stats.loc[top_country, 'Acceptance_Rate']:.2f}% (vs {(total_accepted/len(df)*100):.2f}% overall)\")\n",
    "\n",
    "# Efficiency insight\n",
    "most_efficient = detailed_stats.loc[detailed_stats[\"Acceptance_Rate\"].idxmax()]\n",
    "most_efficient_country = detailed_stats[\"Acceptance_Rate\"].idxmax()\n",
    "print(f\"• {most_efficient_country} with a {most_efficient['Acceptance_Rate']:.1f}% acceptance rate has the highest accepance rate for the last campaign\")\n",
    "print(f\"  (but only {int(most_efficient['Customers_Accepted'])} total acceptances vs {top_country}’s {top_count})\")\n",
    "# Most efficient country: ME with 66.7% acceptance rate\n",
    "# (but only 2 total acceptances vs SP’s 176)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1756043837914,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "p9qkuYcgzMUt"
   },
   "outputs": [],
   "source": [
    "# KEY INSIGHTS:\n",
    "# • SP leads with 176 customers accepting the campaign (52.7% of all acceptances)\n",
    "# • SP has 1091 total customers (48.9% of customer base)\n",
    "# • SP’s acceptance rate for the last campaign is 16.13% (vs 14.98% overall)\n",
    "# • ME with a 66.7% acceptance rate has the highest accepance rate for the last campaign\n",
    "#   (but only 2 total acceptances vs SP’s 176)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P8EcwI0umiyt",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## d. Investigate if there is a discernible pattern in the number of children at home and the total expenditure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 47,
     "status": "ok",
     "timestamp": 1756043837995,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "5MK9bZHbrCfH",
    "outputId": "6abaab3a-7b31-4aae-9c4a-7506c4f85914"
   },
   "outputs": [],
   "source": [
    "# Children at Home vs Total Expenditure Analysis\n",
    "# Investigating patterns between household children count and spending behavior\n",
    "\n",
    "# Examine the data\n",
    "print(\"CHILDREN AT HOME vs TOTAL EXPENDITURE ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# print(f\"Dataset Shape: {df.shape}\")\n",
    "print(f\"Total Records: {len(df)}\")\n",
    "\n",
    "# Data summaries\n",
    "print(\"\\nDATA SUMMARIZATION\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "print(f\"Children count range: {df['Total_Children'].min()} to {df['Total_Children'].max()}\")\n",
    "print(f\"Expenditure range: ${df['Total_Spending'].min()} to ${df['Total_Spending'].max()}\")\n",
    "\n",
    "# Examine distribution of children\n",
    "children_dist = df['Total_Children'].value_counts().sort_index()\n",
    "print(\"\\nDistribution of children at home:\")\n",
    "for children, count in children_dist.items():\n",
    "    percentage = (count / len(df)) * 100\n",
    "    print(f\"  {children} children: {count:4d} households ({percentage:5.1f}%)\")\n",
    "\n",
    "# Calculate summary statistics by number of children\n",
    "print(\"\\nSUMMARY STATISTICS BY CHILDREN COUNT\")\n",
    "print(\"-\" * 45)\n",
    "\n",
    "print(df.groupby('Total_Children')['Total_Spending'].describe().round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1756043838007,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "_XmvNHSNusQs",
    "outputId": "3f092686-62b4-490a-ad89-ed7317c34aaa"
   },
   "outputs": [],
   "source": [
    "# Correlation analysis\n",
    "correlation = df['Total_Children'].corr(df['Total_Spending'])\n",
    "print(f\"\\nPearson correlation coefficient: {correlation:.4f}\")\n",
    "print(f\"Correlation interpretation: {'Strong negative' if correlation < -0.5 else 'Moderate negative' if correlation < -0.3 else 'Weak negative' if correlation < 0 else 'Positive'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 1227,
     "status": "ok",
     "timestamp": 1756043839236,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "8Egh-ZtlvWHe",
    "outputId": "4e114be9-a2b7-4b3d-d7fe-6291f31fbf8c"
   },
   "outputs": [],
   "source": [
    "# Create visualizations\n",
    "\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "# Set style for better-looking plots\n",
    "reset_plot_settings()\n",
    "\n",
    "# plt.style.use('seaborn-v0_8')\n",
    "plt.style.use(\"default\")\n",
    "sns.set_palette(\"viridis\")\n",
    "sns.set_context(\"notebook\", font_scale=1.1)\n",
    "\n",
    "# 2x2 grid\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "plt.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "\n",
    "# 1. Average Expenditure by Children Count (Bar Plot)\n",
    "ax1.set_axisbelow(True)\n",
    "ax1.grid(True, axis=\"y\", alpha=0.3, zorder=0)\n",
    "\n",
    "sns.barplot(\n",
    "    data=df,\n",
    "    x=\"Total_Children\",\n",
    "    y=\"Total_Spending\",\n",
    "    estimator=\"mean\",\n",
    "    ax=ax1,\n",
    "    palette=\"viridis\",\n",
    "    alpha=0.8,\n",
    "    errorbar=None,\n",
    ")\n",
    "\n",
    "# Add value labels on bars\n",
    "bars = ax1.patches\n",
    "\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    ax1.text(\n",
    "        bar.get_x() + bar.get_width() / 2.0,\n",
    "        height + 10,\n",
    "        f\"${height:.0f}\",\n",
    "        fontsize=10,\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "    )\n",
    "\n",
    "ax1.set_title(\"Average Total Expenditure by Number of Children\", fontsize=14)\n",
    "ax1.set_xlabel(\"Number of Children at Home\", fontsize=12)\n",
    "ax1.set_ylabel(\"Average Expenditure ($)\", fontsize=12)\n",
    "\n",
    "# 2. Scatter plot with jitter\n",
    "ax2.set_axisbelow(True)\n",
    "ax2.grid(True, axis=\"y\", alpha=0.3, zorder=0)\n",
    "\n",
    "sns.stripplot(\n",
    "    data=df,\n",
    "    x=\"Total_Children\",\n",
    "    y=\"Total_Spending\",\n",
    "    size=4,\n",
    "    alpha=0.5,\n",
    "    jitter=0.3,\n",
    "    ax=ax2,\n",
    "    hue=\"Total_Children\",\n",
    "    palette=\"viridis\",\n",
    "    legend=False,\n",
    ")\n",
    "\n",
    "# Trendline\n",
    "sns.regplot(\n",
    "    data=df,\n",
    "    x=\"Total_Children\",\n",
    "    y=\"Total_Spending\",\n",
    "    scatter=False,\n",
    "    color=\"red\",\n",
    "    ci=None,\n",
    "    ax=ax2,\n",
    "    line_kws={\n",
    "        \"linestyle\": \"--\",\n",
    "        \"alpha\": 0.8,\n",
    "        \"linewidth\": 2,\n",
    "        \"label\": f\"Trend Line (r={correlation:.3f})\",\n",
    "    },\n",
    ")\n",
    "\n",
    "# Create custom legend\n",
    "\n",
    "# Add trend line to legend\n",
    "legend_elements = []\n",
    "legend_elements.append(\n",
    "    Line2D(\n",
    "        [0],\n",
    "        [0],\n",
    "        color=\"red\",\n",
    "        linestyle=\"--\",\n",
    "        linewidth=2,\n",
    "        label=f\"Trend Line (r = {correlation:.4f})\",\n",
    "    )\n",
    ")\n",
    "\n",
    "ax2.legend(handles=legend_elements, loc=\"best\")\n",
    "\n",
    "ax2.set_title(\"Expenditure vs Children Count\", fontsize=14)\n",
    "ax2.set_xlabel(\"Number of Children at Home\", fontsize=12)\n",
    "ax2.set_ylabel(\"Total Expenditure ($)\", fontsize=12)\n",
    "\n",
    "# 3. Violin Plot for Detailed Distribution\n",
    "ax3.set_axisbelow(True)\n",
    "ax3.grid(True, axis=\"y\", alpha=0.3, zorder=0)\n",
    "\n",
    "violin_data = []\n",
    "violin_labels = []\n",
    "for children in sorted(df[\"Total_Children\"].unique()):\n",
    "    data = df[df[\"Total_Children\"] == children][\"Total_Spending\"].values\n",
    "    if len(data) > 10:  # Only include if enough data points\n",
    "        violin_data.append(data)\n",
    "        violin_labels.append(f\"{children} children\")\n",
    "\n",
    "parts = ax3.violinplot(\n",
    "    violin_data,\n",
    "    positions=range(len(violin_data)),\n",
    "    showmeans=True,\n",
    "    showmedians=True,\n",
    "    showextrema=True,\n",
    ")\n",
    "\n",
    "# Get viridis colors\n",
    "n_violins = len(violin_data)\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, n_violins))\n",
    "\n",
    "for pc, color in zip(parts[\"bodies\"], colors):\n",
    "    pc.set_facecolor(color)\n",
    "    pc.set_alpha(0.7)\n",
    "\n",
    "if \"cbars\" in parts:\n",
    "    parts[\"cbars\"].set_color(\"lightgrey\")\n",
    "    parts[\"cbars\"].set_linewidth(2)\n",
    "    parts[\"cbars\"].set_alpha(0.9)\n",
    "\n",
    "# Customize other elements\n",
    "if \"cmeans\" in parts:\n",
    "    parts[\"cmeans\"].set_color(\"red\")\n",
    "    parts[\"cmeans\"].set_linewidth(3)\n",
    "\n",
    "if \"cmedians\" in parts:\n",
    "    parts[\"cmedians\"].set_color(\"black\")\n",
    "    parts[\"cmedians\"].set_linewidth(2)\n",
    "\n",
    "if \"cmins\" in parts:\n",
    "    parts[\"cmins\"].set_color(\"gray\")\n",
    "    parts[\"cmins\"].set_linewidth(2)\n",
    "\n",
    "if \"cmaxes\" in parts:\n",
    "    parts[\"cmaxes\"].set_color(\"gray\")\n",
    "    parts[\"cmaxes\"].set_linewidth(2)\n",
    "\n",
    "ax3.set_xticks(range(len(violin_labels)), violin_labels)\n",
    "ax3.set_title(\"Expenditure Distribution Density\", fontsize=14)\n",
    "ax3.set_xlabel(\"Number of Children at Home\", fontsize=12)\n",
    "ax3.set_ylabel(\"Total Expenditure ($)\", fontsize=12)\n",
    "\n",
    "# Add legend\n",
    "\n",
    "legend_elements = [\n",
    "    Line2D([0], [0], color=\"red\", linewidth=3, label=\"Mean\"),\n",
    "    Line2D([0], [0], color=\"black\", linewidth=2, label=\"Median\"),\n",
    "]\n",
    "ax3.legend(handles=legend_elements, loc=\"upper right\")\n",
    "\n",
    "# 4. Median vs Mean Comparison\n",
    "ax4.set_axisbelow(True)\n",
    "ax4.grid(True, alpha=0.3, zorder=0)\n",
    "\n",
    "children_counts = sorted(df[\"Total_Children\"].unique())\n",
    "means = [\n",
    "    df[df[\"Total_Children\"] == c][\"Total_Spending\"].mean() for c in children_counts\n",
    "]\n",
    "medians = [\n",
    "    df[df[\"Total_Children\"] == c][\"Total_Spending\"].median() for c in children_counts\n",
    "]\n",
    "\n",
    "ax4.plot(\n",
    "    children_counts,\n",
    "    means,\n",
    "    \"o-\",\n",
    "    linewidth=2,\n",
    "    markersize=8,\n",
    "    label=\"Mean\",\n",
    "    color=\"red\",\n",
    "    markeredgecolor=\"black\",\n",
    ")\n",
    "ax4.plot(\n",
    "    children_counts,\n",
    "    medians,\n",
    "    \"s-\",\n",
    "    linewidth=2,\n",
    "    markersize=8,\n",
    "    label=\"Median\",\n",
    "    color=\"black\",\n",
    "    markeredgecolor=\"black\",\n",
    ")\n",
    "\n",
    "ax4.set_title(\"Mean vs Median Expenditure\\nby Children Count\", fontsize=14)\n",
    "ax4.set_xlabel(\"Number of Children at Home\", fontsize=12)\n",
    "ax4.set_ylabel(\"Expenditure ($)\", fontsize=12)\n",
    "ax4.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1756043839282,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "q4m2iXAVjPSV",
    "outputId": "24ba1ddf-dc2a-4937-c798-1e24e6f3e6c7"
   },
   "outputs": [],
   "source": [
    "# Additional Analysis: Effect Size and Practical Significance\n",
    "print(\"\\nDETAILED FINDINGS & INSIGHTS\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Calculate percentage decrease in spending\n",
    "spending_0_children = df[df['Total_Children']==0]['Total_Spending'].mean()\n",
    "spending_1_children = df[df['Total_Children']==1]['Total_Spending'].mean()\n",
    "spending_2_children = df[df['Total_Children']==2]['Total_Spending'].mean()\n",
    "spending_3_children = df[df['Total_Children']==3]['Total_Spending'].mean()\n",
    "\n",
    "decrease_1_child = ((spending_0_children - spending_1_children) / spending_0_children) * 100\n",
    "decrease_2_children = ((spending_0_children - spending_2_children) / spending_0_children) * 100\n",
    "decrease_3_children = ((spending_0_children - spending_3_children) / spending_0_children) * 100\n",
    "\n",
    "print(\"\\nEXPENDITURE:\")\n",
    "print(f\"• 0 children: ${spending_0_children:.0f} average expenditure\")\n",
    "print(f\"• 1 child:    ${spending_1_children:.0f} average expenditure ({decrease_1_child:.1f}% decrease)\")\n",
    "print(f\"• 2 children: ${spending_2_children:.0f} average expenditure ({decrease_2_children:.1f}% decrease)\")\n",
    "print(f\"• 3 children: ${spending_3_children:.0f} average expenditure ({decrease_3_children:.1f}% decrease)\")\n",
    "\n",
    "print(\"\\nIMPLICATIONS:\")\n",
    "print(f\"• Childless households represent {children_dist[0]/len(df)*100:.1f}% of customers but highest value\")\n",
    "print(f\"• Average spending ratio (0 vs 1 child): {spending_0_children/spending_1_children:.1f}:1\")\n",
    "print(f\"• Average spending ratio (0 vs 2 children): {spending_0_children/spending_2_children:.1f}:1\")\n",
    "print(f\"• Average spending ratio (0 vs 3+ children): {spending_0_children/spending_3_children:.1f}:1\")\n",
    "print(\"• Clear market segmentation opportunity based on family status\")\n",
    "\n",
    "print(\"\\nCONCLUSION:\")\n",
    "print(\"• There is an inverse relationship between\")\n",
    "print(\"  the number of children at home and total expenditure.\")\n",
    "print(\"• This pattern is consistent across all statistical measures\")\n",
    "\n",
    "# Create a final summary table\n",
    "print(\"\\nSUMMARY TABLE:\")\n",
    "print(\"=\" * 80)\n",
    "summary_display = df.groupby('Total_Children')['Total_Spending'].agg([\n",
    "    ('Sample Size', 'count'),\n",
    "    ('Average Spending', 'mean'),\n",
    "    ('Median Spending', 'median'),\n",
    "    ('Standard Deviation', 'std')\n",
    "]).copy() # type: ignore\n",
    "# print(summary_display.round(2))\n",
    "\n",
    "summary_display = summary_display.round(2)\n",
    "summary_display['% of Total'] = (summary_display['Sample Size'] / len(df) * 100).round(1)\n",
    "summary_display['Spending Ratio'] = (summary_display['Average Spending'] / spending_0_children).round(2)\n",
    "summary_display = summary_display.reset_index()\n",
    "summary_display = summary_display.rename(columns={'Total_Children': 'Number of Children'})\n",
    "summary_display = summary_display.set_index('Number of Children')\n",
    "print(summary_display.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 37,
     "status": "ok",
     "timestamp": 1756043839341,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "SOCcgGbYvRDY"
   },
   "outputs": [],
   "source": [
    "# DETAILED FINDINGS & INSIGHTS\n",
    "# ========================================\n",
    "\n",
    "# EXPENDITURE:\n",
    "# • 0 children: $1106 average expenditure\n",
    "# • 1 child:    $473 average expenditure (57.2% decrease)\n",
    "# • 2 children: $246 average expenditure (77.7% decrease)\n",
    "# • 3 children: $275 average expenditure (75.2% decrease)\n",
    "\n",
    "# IMPLICATIONS:\n",
    "# • Childless households represent 28.4% of customers but highest value\n",
    "# • Average spending ratio (0 vs 1 child): 2.3:1\n",
    "# • Average spending ratio (0 vs 2 children): 4.5:1\n",
    "# • Average spending ratio (0 vs 3+ children): 4.0:1\n",
    "# • Clear market segmentation opportunity based on family status\n",
    "\n",
    "# CONCLUSION:\n",
    "# • There is an inverse relationship between\n",
    "#   the number of children at home and total expenditure.\n",
    "# • This pattern is consistent across all statistical measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xs0Ev12RnTpe"
   },
   "source": [
    "## e. Analyze the educational background of customers who lodged complaints in the last two years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 625
    },
    "executionInfo": {
     "elapsed": 2327,
     "status": "ok",
     "timestamp": 1756043978954,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "eJYZdw9yYSxO",
    "outputId": "708a156f-85c5-4e22-9dd3-d3d5c040d1a8"
   },
   "outputs": [],
   "source": [
    "# --- Filter for last 2 years of data ---\n",
    "latest_date = df[\"Dt_Customer\"].max()\n",
    "most_recent_date = df[\"Dt_Customer\"].min()\n",
    "cutoff_date = latest_date - pd.DateOffset(years=2)\n",
    "\n",
    "complaints_recent = df[df[\"Dt_Customer\"] >= cutoff_date].copy()\n",
    "complaints_recent[\"YearMonth\"] = complaints_recent[\"Dt_Customer\"].dt.to_period(\"M\")\n",
    "\n",
    "# --- Map education numbers back to labels ---\n",
    "edu_map = {1: \"Secondary\", 2: \"Bachelor\", 3: \"Master\", 4: \"PhD\"}\n",
    "complaints_recent[\"Education\"] = complaints_recent[\"Education_Encoded\"].map(edu_map)\n",
    "\n",
    "# --- Define order & palettes ---\n",
    "edu_order = [\"Secondary\", \"Bachelor\", \"Master\", \"PhD\"]\n",
    "# edu_palette = dict(zip(edu_order, sns.color_palette(\"Set2\", len(edu_order))))\n",
    "# edu_palette = dict(zip(edu_order, sns.color_palette(\"tab10\", len(edu_order))))\n",
    "edu_palette = dict(zip(edu_order, sns.color_palette(\"Dark2\", len(edu_order))))\n",
    "complain_palette = {\n",
    "    0: \"#cccccc\",\n",
    "    1: \"#440154\",\n",
    "}  # grey = no complaint, purple = complaint\n",
    "\n",
    "# --- Counts (complaints only) ---\n",
    "edu_counts = complaints_recent.loc[\n",
    "    complaints_recent[\"Complain\"] == 1, \"Education\"\n",
    "].value_counts()\n",
    "\n",
    "# --- Complaint vs No Complaint proportions ---\n",
    "complaint_share = (\n",
    "    complaints_recent.groupby(\"Education\")[\"Complain\"]\n",
    "    .value_counts(normalize=True)\n",
    "    .rename(\"Proportion\")\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "stacked_share = complaint_share.pivot(\n",
    "    index=\"Education\", columns=\"Complain\", values=\"Proportion\"\n",
    ").fillna(0)\n",
    "\n",
    "# --- Create subplot grid ---\n",
    "reset_plot_settings()\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Countplot (Complaints only)\n",
    "ax1.set_axisbelow(True)\n",
    "ax1.grid(True, axis=\"y\", alpha=0.3, zorder=0)\n",
    "\n",
    "sns.countplot(\n",
    "    data=complaints_recent[complaints_recent[\"Complain\"] == 1],\n",
    "    x=\"Education\",\n",
    "    order=edu_order,\n",
    "    palette=edu_palette,\n",
    "    ax=ax1,\n",
    ")\n",
    "ax1.set_title(\"Complaints by Education (Counts, Last 2 Years)\", fontsize=14)\n",
    "ax1.set_xlabel(\"Education\", fontsize=12)\n",
    "ax1.set_ylabel(\"Count\", fontsize=12)\n",
    "ax1.tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "# 2. Pie chart (Complaints only)\n",
    "ax2.pie(\n",
    "    edu_counts,\n",
    "    labels=edu_counts.index,\n",
    "    autopct=\"%1.1f%%\",\n",
    "    startangle=90,\n",
    "    colors=[edu_palette[edu] for edu in edu_counts.index],\n",
    ")\n",
    "ax2.set_title(\"Complaints by Education (Pie, Last 2 Years)\")\n",
    "\n",
    "# 3. Trend over time (Complaints only, chronological order)\n",
    "ax3.set_axisbelow(True)\n",
    "ax3.grid(True, axis=\"y\", alpha=0.3, zorder=0)\n",
    "\n",
    "order = sorted(complaints_recent[\"YearMonth\"].unique())\n",
    "sns.countplot(\n",
    "    data=complaints_recent[complaints_recent[\"Complain\"] == 1],\n",
    "    x=\"YearMonth\",\n",
    "    hue=\"Education\",\n",
    "    order=order,\n",
    "    hue_order=edu_order,\n",
    "    palette=edu_palette,\n",
    "    ax=ax3,\n",
    ")\n",
    "ax3.set_title(\"Complaint Trends by Education (Last 2 Years)\", fontsize=14)\n",
    "ax3.set_xlabel(\"Year-Month\", fontsize=12)\n",
    "ax3.set_ylabel(\"Complaint Count\", fontsize=12)\n",
    "\n",
    "n_ticks = 6  # Desired number of ticks\n",
    "step = max(1, len(order) // n_ticks)\n",
    "tick_positions = range(0, len(order), step)\n",
    "tick_labels = [order[i] for i in tick_positions]\n",
    "\n",
    "ax3.set_xticks(tick_positions)\n",
    "ax3.set_xticklabels(tick_labels, rotation=45, ha=\"right\")\n",
    "ax3.legend(title=\"Education\")\n",
    "\n",
    "# 4. 100% Stacked Bar (Complaints vs No Complaints)\n",
    "ax4.set_axisbelow(True)\n",
    "ax4.grid(True, axis=\"y\", alpha=0.3, zorder=0)\n",
    "\n",
    "stacked_share.loc[edu_order].plot(\n",
    "    kind=\"bar\",\n",
    "    stacked=True,\n",
    "    ax=ax4,\n",
    "    color=[complain_palette[c] for c in stacked_share.columns],\n",
    "    width=0.7,\n",
    "    edgecolor=\"white\",  # Add white borders between segments\n",
    "    linewidth=0.75,\n",
    ")\n",
    "\n",
    "# Add percentage labels on each segment\n",
    "for i, education in enumerate(edu_order):\n",
    "    # Get the values for this education level\n",
    "    no_complaint_pct = (\n",
    "        stacked_share.loc[education, 0] * 100\n",
    "    )  # Assuming 0 = No Complaint\n",
    "    complaint_pct = stacked_share.loc[education, 1] * 100  # Assuming 1 = Complaint\n",
    "\n",
    "    # Add label for \"No Complaint\" segment (bottom part)\n",
    "    ax4.text(\n",
    "        i,\n",
    "        no_complaint_pct / 200,\n",
    "        f\"{no_complaint_pct:.1f}%\",\n",
    "        ha=\"center\",\n",
    "        va=\"center\",\n",
    "        fontweight=\"bold\",\n",
    "        fontsize=10,\n",
    "    )\n",
    "\n",
    "# Titles and labels\n",
    "# ax4.set_title(\"Customer Complaint Rates by Education Level\", fontsize=14)\n",
    "ax4.set_title(\"Proportion of Complaints vs No Complaints by Education\", fontsize=14)\n",
    "ax4.set_ylabel(\"Proportion of Customers\", fontsize=12)\n",
    "ax4.set_xlabel(\"Education Level\", fontsize=12)\n",
    "ax4.set_xticklabels(edu_order, rotation=45, ha=\"right\")\n",
    "\n",
    "# Set y-axis to show percentages\n",
    "ax4.yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: \"{:.0%}\".format(y)))\n",
    "\n",
    "ax4.legend(\n",
    "    [\"No Complaint\", \"Complaint\"],\n",
    "    title=\"Customer Complain\",\n",
    "    bbox_to_anchor=(1.05, 1),\n",
    "    loc=\"upper left\",\n",
    "    frameon=True,\n",
    "    fancybox=True,\n",
    ")\n",
    "\n",
    "# ax4.spines['top'].set_visible(False)\n",
    "# ax4.spines['right'].set_visible(False)\n",
    "ax4.set_ylim(0, 1.05)  # Add some space at the top\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1756043840080,
     "user": {
      "displayName": "Scott Clement",
      "userId": "09077177954652264696"
     },
     "user_tz": 420
    },
    "id": "n_FavILWtKNz"
   },
   "outputs": [],
   "source": [
    "# Primary Insights:\n",
    "# - Bachelor's Degree Holders Dominate Complaints\n",
    "# - Bachelor's represent 70% of all complaints (pie chart) and have the highest absolute count (14 complaints)\n",
    "# - Complaint Rates Are Consistently Low Across Education Levels\n",
    "#   - All education groups show 98.8-100% \"No Complaint\" rates (stacked bar chart)\n",
    "#   - Secondary education shows 100% satisfaction, while Bachelor's, Master's, and PhD all hover around 98.8-99.1%\n",
    "#   - The differences between education levels are minimal (less than 2 percentage points)\n",
    "# - Complaint Activity Is Sporadic\n",
    "#   - The time trend shows complaints are infrequent and clustered\n",
    "#   - Most time periods have zero complaints, with occasional spikes\n",
    "#   - Bachelor's degree holders appear in most complaint periods"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "DYtp9erX19WK",
    "GVuHVbMHfVWG",
    "DjqH08PYfbk2",
    "PmGaLIPafffT",
    "9sfn05JofN6G",
    "qz6bFMvPfGBu",
    "nE1oQ4OXfAAG",
    "c6WX5R4lezKn",
    "aXL7WXdsgQ2n",
    "FWjMLJSFd1dB",
    "4-SEZkZleCWN",
    "VCZRsaNXeSPe",
    "wgFBL7MPeYAr",
    "2LPkZ9YtmPoH",
    "P8EcwI0umiyt"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
